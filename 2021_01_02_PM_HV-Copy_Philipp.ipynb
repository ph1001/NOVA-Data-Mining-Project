{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do:\n",
    "- Deal with records that have RDATE before ADATE\n",
    "- (?) (Probably doesn't make sense) Do something with this information (from metadata text file):\n",
    "                            LL mailings had labels only\n",
    "                            WL mailings had labels only\n",
    "                            CC mailings are calendars with stickers but do\n",
    "                               not have labels\n",
    "                            FS mailings are blank cards that fold into\n",
    "                               thirds with labels\n",
    "                            NK mailings are blank cards with labels\n",
    "                            SK mailings are blank cards with labels\n",
    "                            TK mailings have thank you printed on the\n",
    "                               outside with labels\n",
    "                            GK mailings are general greeting cards (an\n",
    "                               assortment of birthday, sympathy, blank, & get\n",
    "                               well) with labels\n",
    "                            XK mailings are Christmas cards with labels\n",
    "                            X1 mailings have labels and a notepad\n",
    "                            G1 mailings have labels and a notepad\n",
    "- Use the variable that is most correlated with 'Age' ('Age' is yet to be created from 'DOB') to fill in the missing values of 'Age' (using a linear model for example)\n",
    "- As a final check for outlier detection, use DBSCAN to see if all outliers were excluded\n",
    "- Henrique's notes:\n",
    "    - I had one note in my notebook we should turn ODATE into number of months for RFA matters maybe and DOB to days\n",
    "        - -> <span style=\"color:red\">Turned all date features into days relative to ADATE_2</span>\n",
    "    - Another one saying that NOEXCH could be remove. Check it out a see if you agree\n",
    "        - <span style=\"color:red\">This one doesn't seem too bad to me so far actually</span>\n",
    "- Decide what to do with 'HOMEOWNR' (Home Owner Flag, H = Home owner, U = Unknown)\n",
    "    - pd.unique(donors.HOMEOWNR) ---> array([nan, 'H', 'U'], dtype=object)\n",
    "    - Could be incuded as: \"Home owner\" = 1, \"No home owner\" = 0, \"Unknown\" = nan\n",
    "    - But does it make sense to use binary variables for clustering?\n",
    "- What was done in the \"clustering\" lab: Use DBSCAN to remove outliers. Do the clustering on the inliers. Then in the end add each outlier to the closest cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Insights from the Q&A on Thursday, 10. Dec. 2020:</span>\n",
    "\n",
    "<span style=\"color:red\">**See text file \"Notes Q&A 10. Dec. 2020\" in folder \"PDFs and notes\"**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import dateutil.relativedelta\n",
    "from datetime import date\n",
    "import math\n",
    "from math import ceil\n",
    "\n",
    "# Import data scalers\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import Encoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Import clustering functions\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import estimate_bandwidth\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Import Visualisations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import Imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# for better resolution plots\n",
    "%config InlineBackend.figure_format = 'retina' # optionally, you can change 'svg' to 'retina'\n",
    "\n",
    "# Seeting seaborn style\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off warnings\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "donors = pd.read_csv(os.path.join('Data and metadata', 'donors.csv'), sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>MAILCODE</th>\n",
       "      <th>PVASTATE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>RECINHSE</th>\n",
       "      <th>...</th>\n",
       "      <th>AVGGIFT</th>\n",
       "      <th>CONTROLN</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>GEOCODE2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>GRI</td>\n",
       "      <td>0</td>\n",
       "      <td>IL</td>\n",
       "      <td>61081</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1957-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>7.741935</td>\n",
       "      <td>95515</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>BOA</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>91326</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1972-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>148535</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>G</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>AMH</td>\n",
       "      <td>1</td>\n",
       "      <td>NC</td>\n",
       "      <td>27017</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>7.481481</td>\n",
       "      <td>15078</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>BRY</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>95953</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>6.812500</td>\n",
       "      <td>172556</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>FL</td>\n",
       "      <td>33176</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1940-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>...</td>\n",
       "      <td>6.864865</td>\n",
       "      <td>7112</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95407</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>ASE</td>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>99504</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>184568</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95408</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>DCD</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>77379</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>122706</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95409</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>MBC</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "      <td>48910</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1958-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>189641</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95410</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>PRV</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>91320</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1960-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>...</td>\n",
       "      <td>12.146341</td>\n",
       "      <td>4693</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95411</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>MCC</td>\n",
       "      <td>2</td>\n",
       "      <td>NC</td>\n",
       "      <td>28409</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1938-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>...</td>\n",
       "      <td>96.794872</td>\n",
       "      <td>185114</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95412 rows × 475 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ODATEDW OSOURCE  TCODE STATE    ZIP MAILCODE PVASTATE         DOB  \\\n",
       "0      2009-01-01     GRI      0    IL  61081                    1957-12-01   \n",
       "1      2014-01-01     BOA      1    CA  91326                    1972-02-01   \n",
       "2      2010-01-01     AMH      1    NC  27017                           NaN   \n",
       "3      2007-01-01     BRY      0    CA  95953                    1948-01-01   \n",
       "4      2006-01-01              0    FL  33176                    1940-01-01   \n",
       "...           ...     ...    ...   ...    ...      ...      ...         ...   \n",
       "95407  2016-01-01     ASE      1    AK  99504                           NaN   \n",
       "95408  2016-01-01     DCD      1    TX  77379                    1970-01-01   \n",
       "95409  2015-01-01     MBC      1    MI  48910                    1958-01-01   \n",
       "95410  2006-01-01     PRV      0    CA  91320                    1960-05-01   \n",
       "95411  2008-01-01     MCC      2    NC  28409                    1938-01-01   \n",
       "\n",
       "      NOEXCH RECINHSE  ...    AVGGIFT CONTROLN HPHONE_D RFA_2R RFA_2F RFA_2A  \\\n",
       "0          0           ...   7.741935    95515        0      L      4      E   \n",
       "1          0           ...  15.666667   148535        0      L      2      G   \n",
       "2          0           ...   7.481481    15078        1      L      4      E   \n",
       "3          0           ...   6.812500   172556        1      L      4      E   \n",
       "4          0        X  ...   6.864865     7112        1      L      2      F   \n",
       "...      ...      ...  ...        ...      ...      ...    ...    ...    ...   \n",
       "95407      0           ...  25.000000   184568        0      L      1      G   \n",
       "95408      0           ...  20.000000   122706        1      L      1      F   \n",
       "95409      0           ...   8.285714   189641        1      L      3      E   \n",
       "95410      0        X  ...  12.146341     4693        1      L      4      F   \n",
       "95411      0        X  ...  96.794872   185114        1      L      1      G   \n",
       "\n",
       "      MDMAUD_R MDMAUD_F MDMAUD_A GEOCODE2  \n",
       "0            X        X        X        C  \n",
       "1            X        X        X        A  \n",
       "2            X        X        X        C  \n",
       "3            X        X        X        C  \n",
       "4            X        X        X        A  \n",
       "...        ...      ...      ...      ...  \n",
       "95407        X        X        X        C  \n",
       "95408        X        X        X        A  \n",
       "95409        X        X        X        B  \n",
       "95410        X        X        X        A  \n",
       "95411        C        1        C        C  \n",
       "\n",
       "[95412 rows x 475 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original features in a list\n",
    "features_orig = list(donors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for checking the types of all elements of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types present in this feature:\n",
      "{<class 'str'>}\n",
      "Items that have type <class 'float'> :\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "feature = 'ADATE_2'\n",
    "type_items_to_retieve = float\n",
    "type_set = set()\n",
    "list_ = []\n",
    "for item in donors[feature]:\n",
    "    type_ = type(item)\n",
    "    type_set.add(type_)\n",
    "    if type_ == type_items_to_retieve:\n",
    "        list_.append(item)\n",
    "print('Types present in this feature:')\n",
    "print(type_set)\n",
    "print('Items that have type', type_items_to_retieve, ':')\n",
    "print(pd.unique(list_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate metric features from non-metric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>MAILCODE</th>\n",
       "      <th>PVASTATE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>RECINHSE</th>\n",
       "      <th>...</th>\n",
       "      <th>AVGGIFT</th>\n",
       "      <th>CONTROLN</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>GEOCODE2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>GRI</td>\n",
       "      <td>0</td>\n",
       "      <td>IL</td>\n",
       "      <td>61081</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1957-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>7.741935</td>\n",
       "      <td>95515</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>BOA</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>91326</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1972-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>148535</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>G</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>AMH</td>\n",
       "      <td>1</td>\n",
       "      <td>NC</td>\n",
       "      <td>27017</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>7.481481</td>\n",
       "      <td>15078</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>BRY</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>95953</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>6.812500</td>\n",
       "      <td>172556</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>FL</td>\n",
       "      <td>33176</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1940-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>...</td>\n",
       "      <td>6.864865</td>\n",
       "      <td>7112</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 475 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ODATEDW OSOURCE  TCODE STATE    ZIP MAILCODE PVASTATE         DOB  \\\n",
       "0  2009-01-01     GRI      0    IL  61081                    1957-12-01   \n",
       "1  2014-01-01     BOA      1    CA  91326                    1972-02-01   \n",
       "2  2010-01-01     AMH      1    NC  27017                           NaN   \n",
       "3  2007-01-01     BRY      0    CA  95953                    1948-01-01   \n",
       "4  2006-01-01              0    FL  33176                    1940-01-01   \n",
       "\n",
       "  NOEXCH RECINHSE  ...    AVGGIFT CONTROLN HPHONE_D RFA_2R RFA_2F RFA_2A  \\\n",
       "0      0           ...   7.741935    95515        0      L      4      E   \n",
       "1      0           ...  15.666667   148535        0      L      2      G   \n",
       "2      0           ...   7.481481    15078        1      L      4      E   \n",
       "3      0           ...   6.812500   172556        1      L      4      E   \n",
       "4      0        X  ...   6.864865     7112        1      L      2      F   \n",
       "\n",
       "  MDMAUD_R MDMAUD_F MDMAUD_A GEOCODE2  \n",
       "0        X        X        X        C  \n",
       "1        X        X        X        A  \n",
       "2        X        X        X        C  \n",
       "3        X        X        X        C  \n",
       "4        X        X        X        A  \n",
       "\n",
       "[5 rows x 475 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at top of remaining dataset\n",
    "donors.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype of feature HOMEOWNR : object\n",
      "First non nan element of this feature:  \n",
      "Class of the first element of this feature: <class 'str'>\n",
      "Unique values of feature HOMEOWNR : [' ' 'H' 'U']\n"
     ]
    }
   ],
   "source": [
    "## Obtain information of the type of a certain feature\n",
    "feature = 'HOMEOWNR'\n",
    "\n",
    "# Print its type\n",
    "print('dtype of feature', feature, ':', donors.dtypes[feature])\n",
    "\n",
    "# Take a closer look at the first non nan element of it\n",
    "first_non_na_element = donors[feature][~donors[feature].isna()].iloc[0]\n",
    "print('First non nan element of this feature:', first_non_na_element)\n",
    "print('Class of the first element of this feature:', type(first_non_na_element))\n",
    "\n",
    "# View the unique values of this feature\n",
    "# print('Sorted unique values of feature', feature, ':', np.sort(pd.unique(donors[feature])))\n",
    "print('Unique values of feature', feature, ':', pd.unique(donors[feature]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of metric features: 398\n"
     ]
    }
   ],
   "source": [
    "# Create a list with the metric features\n",
    "# Including dates and other variables that might still be Strings at this point\n",
    "# Will use 'to_num' on all metric features in the next step\n",
    "metric_features = ['ODATEDW',\n",
    " 'DOB',\n",
    " 'NUMCHLD',\n",
    " 'INCOME',\n",
    " 'WEALTH1',\n",
    " 'HIT',\n",
    "                   # Above: Information about the donor\n",
    "                   # Below: About the number of times the donor has responded to other types of mail order offers\n",
    " 'MBCRAFT',\n",
    " 'MBGARDEN',\n",
    " 'MBBOOKS',\n",
    " 'MBCOLECT',\n",
    " 'MAGFAML',\n",
    " 'MAGFEM',\n",
    " 'MAGMALE',\n",
    " 'PUBGARDN',\n",
    " 'PUBCULIN',\n",
    " 'PUBHLTH',\n",
    " 'PUBDOITY',\n",
    " 'PUBNEWFN',\n",
    " 'PUBPHOTO',\n",
    " 'PUBOPP',\n",
    "                   # Below: Data from third party regarding the household or neighborhood (According to David Silva) \n",
    " 'MALEMILI',\n",
    " 'MALEVET',\n",
    " 'VIETVETS',\n",
    " 'WWIIVETS',\n",
    " 'LOCALGOV',\n",
    " 'STATEGOV',\n",
    " 'FEDGOV',         \n",
    " 'SOLP3',\n",
    " 'SOLIH',\n",
    " 'WEALTH2',\n",
    "                   # Below: About donor's neighbourhood\n",
    " 'POP901',\n",
    " 'POP902',\n",
    " 'POP903',\n",
    " 'POP90C1',\n",
    " 'POP90C2',\n",
    " 'POP90C3',\n",
    " 'POP90C4',\n",
    " 'POP90C5',\n",
    " 'ETH1',\n",
    " 'ETH2',\n",
    " 'ETH3',\n",
    " 'ETH4',\n",
    " 'ETH5',\n",
    " 'ETH6',\n",
    " 'ETH7',\n",
    " 'ETH8',\n",
    " 'ETH9',\n",
    " 'ETH10',\n",
    " 'ETH11',\n",
    " 'ETH12',\n",
    " 'ETH13',\n",
    " 'ETH14',\n",
    " 'ETH15',\n",
    " 'ETH16',              \n",
    " 'AGE901',\n",
    " 'AGE902',\n",
    " 'AGE903',\n",
    " 'AGE904',\n",
    " 'AGE905',\n",
    " 'AGE906',\n",
    " 'AGE907',\n",
    " 'CHIL1',\n",
    " 'CHIL2',\n",
    " 'CHIL3',\n",
    " 'AGEC1',\n",
    " 'AGEC2',\n",
    " 'AGEC3',\n",
    " 'AGEC4',\n",
    " 'AGEC5',\n",
    " 'AGEC6',\n",
    " 'AGEC7',\n",
    " 'CHILC1',\n",
    " 'CHILC2',\n",
    " 'CHILC3',\n",
    " 'CHILC4',\n",
    " 'CHILC5',\n",
    " 'HHAGE1',\n",
    " 'HHAGE2',\n",
    " 'HHAGE3',\n",
    " 'HHN1',\n",
    " 'HHN2',\n",
    " 'HHN3',\n",
    " 'HHN4',\n",
    " 'HHN5',\n",
    " 'HHN6',\n",
    " 'MARR1',\n",
    " 'MARR2',\n",
    " 'MARR3',\n",
    " 'MARR4',           \n",
    " 'HHP1',\n",
    " 'HHP2',\n",
    " 'DW1',\n",
    " 'DW2',\n",
    " 'DW3',\n",
    " 'DW4',\n",
    " 'DW5',\n",
    " 'DW6',\n",
    " 'DW7',\n",
    " 'DW8',\n",
    " 'DW9',\n",
    " 'HV1',\n",
    " 'HV2',\n",
    " 'HV3',\n",
    " 'HV4',\n",
    " 'HU1',\n",
    " 'HU2',\n",
    " 'HU3',\n",
    " 'HU4',\n",
    " 'HU5',                  \n",
    " 'HHD1',\n",
    " 'HHD2',\n",
    " 'HHD3',\n",
    " 'HHD4',\n",
    " 'HHD5',\n",
    " 'HHD6',\n",
    " 'HHD7',\n",
    " 'HHD8',\n",
    " 'HHD9',\n",
    " 'HHD10',\n",
    " 'HHD11',\n",
    " 'HHD12',\n",
    " 'ETHC1',\n",
    " 'ETHC2',\n",
    " 'ETHC3',\n",
    " 'ETHC4',\n",
    " 'ETHC5',\n",
    " 'ETHC6',\n",
    " 'HVP1',\n",
    " 'HVP2',\n",
    " 'HVP3',\n",
    " 'HVP4',\n",
    " 'HVP5',\n",
    " 'HVP6',                  \n",
    " 'HUR1',\n",
    " 'HUR2',\n",
    " 'RHP1',\n",
    " 'RHP2',\n",
    " 'RHP3',\n",
    " 'RHP4',\n",
    " 'HUPA1',\n",
    " 'HUPA2',\n",
    " 'HUPA3',\n",
    " 'HUPA4',\n",
    " 'HUPA5',\n",
    " 'HUPA6',\n",
    " 'HUPA7',\n",
    " 'RP1',\n",
    " 'RP2',\n",
    " 'RP3',\n",
    " 'RP4',                 \n",
    " 'IC1',\n",
    " 'IC2',\n",
    " 'IC3',\n",
    " 'IC4',\n",
    " 'IC5',\n",
    " 'IC6',\n",
    " 'IC7',\n",
    " 'IC8',\n",
    " 'IC9',\n",
    " 'IC10',\n",
    " 'IC11',\n",
    " 'IC12',\n",
    " 'IC13',\n",
    " 'IC14',\n",
    " 'IC15',\n",
    " 'IC16',\n",
    " 'IC17',\n",
    " 'IC18',\n",
    " 'IC19',\n",
    " 'IC20',\n",
    " 'IC21',\n",
    " 'IC22',\n",
    " 'IC23',           \n",
    " 'HHAS1',\n",
    " 'HHAS2',\n",
    " 'HHAS3',\n",
    " 'HHAS4',\n",
    " 'MC1',\n",
    " 'MC2',\n",
    " 'MC3',\n",
    " 'TPE1',\n",
    " 'TPE2',\n",
    " 'TPE3',\n",
    " 'TPE4',\n",
    " 'TPE5',\n",
    " 'TPE6',\n",
    " 'TPE7',\n",
    " 'TPE8',\n",
    " 'TPE9',\n",
    " 'PEC1',\n",
    " 'PEC2',\n",
    " 'TPE10',\n",
    " 'TPE11',\n",
    " 'TPE12',\n",
    " 'TPE13',\n",
    " 'LFC1',\n",
    " 'LFC2',\n",
    " 'LFC3',\n",
    " 'LFC4',\n",
    " 'LFC5',\n",
    " 'LFC6',\n",
    " 'LFC7',\n",
    " 'LFC8',\n",
    " 'LFC9',\n",
    " 'LFC10',\n",
    " 'OCC1',\n",
    " 'OCC2',\n",
    " 'OCC3',\n",
    " 'OCC4',\n",
    " 'OCC5',\n",
    " 'OCC6',\n",
    " 'OCC7',\n",
    " 'OCC8',\n",
    " 'OCC9',\n",
    " 'OCC10',\n",
    " 'OCC11',\n",
    " 'OCC12',\n",
    " 'OCC13',\n",
    " 'EIC1',\n",
    " 'EIC2',\n",
    " 'EIC3',\n",
    " 'EIC4',\n",
    " 'EIC5',\n",
    " 'EIC6',\n",
    " 'EIC7',\n",
    " 'EIC8',\n",
    " 'EIC9',\n",
    " 'EIC10',\n",
    " 'EIC11',\n",
    " 'EIC12',\n",
    " 'EIC13',\n",
    " 'EIC14',\n",
    " 'EIC15',\n",
    " 'EIC16',\n",
    " 'OEDC1',\n",
    " 'OEDC2',\n",
    " 'OEDC3',\n",
    " 'OEDC4',\n",
    " 'OEDC5',\n",
    " 'OEDC6',\n",
    " 'OEDC7',\n",
    " 'EC1',\n",
    " 'EC2',\n",
    " 'EC3',\n",
    " 'EC4',\n",
    " 'EC5',\n",
    " 'EC6',\n",
    " 'EC7',\n",
    " 'EC8',\n",
    " 'SEC1',\n",
    " 'SEC2',\n",
    " 'SEC3',\n",
    " 'SEC4',\n",
    " 'SEC5',\n",
    " 'AFC1',\n",
    " 'AFC2',\n",
    " 'AFC3',\n",
    " 'AFC4',\n",
    " 'AFC5',\n",
    " 'AFC6',\n",
    " 'VC1',\n",
    " 'VC2',\n",
    " 'VC3',\n",
    " 'VC4',\n",
    " 'ANC1',\n",
    " 'ANC2',\n",
    " 'ANC3',\n",
    " 'ANC4',\n",
    " 'ANC5',\n",
    " 'ANC6',\n",
    " 'ANC7',\n",
    " 'ANC8',\n",
    " 'ANC9',\n",
    " 'ANC10',\n",
    " 'ANC11',\n",
    " 'ANC12',\n",
    " 'ANC13',\n",
    " 'ANC14',\n",
    " 'ANC15',\n",
    " 'POBC1',\n",
    " 'POBC2',\n",
    " 'LSC1',\n",
    " 'LSC2',\n",
    " 'LSC3',\n",
    " 'LSC4',\n",
    " 'VOC1',\n",
    " 'VOC2',\n",
    " 'VOC3',\n",
    " 'HC1',\n",
    " 'HC2',\n",
    " 'HC3',\n",
    " 'HC4',\n",
    " 'HC5',\n",
    " 'HC6',\n",
    " 'HC7',\n",
    " 'HC8',\n",
    " 'HC9',\n",
    " 'HC10',\n",
    " 'HC11',\n",
    " 'HC12',\n",
    " 'HC13',\n",
    " 'HC14',\n",
    " 'HC15',\n",
    " 'HC16',\n",
    " 'HC17',\n",
    " 'HC18',\n",
    " 'HC19',\n",
    " 'HC20',\n",
    " 'HC21',\n",
    " 'MHUC1',\n",
    " 'MHUC2',\n",
    " 'AC1',\n",
    " 'AC2',\n",
    "                   # Above: About donor's neighbourhood      \n",
    "                   # Below: Date promotion X was mailed\n",
    " 'ADATE_2',\n",
    " 'ADATE_3',\n",
    " 'ADATE_4',\n",
    " 'ADATE_5',\n",
    " 'ADATE_6',\n",
    " 'ADATE_7',\n",
    " 'ADATE_8',\n",
    " 'ADATE_9',\n",
    " 'ADATE_10',\n",
    " 'ADATE_11',\n",
    " 'ADATE_12',\n",
    " 'ADATE_13',\n",
    " 'ADATE_14',\n",
    " 'ADATE_15',\n",
    " 'ADATE_16',\n",
    " 'ADATE_17',\n",
    " 'ADATE_18',\n",
    " 'ADATE_19',\n",
    " 'ADATE_20',\n",
    " 'ADATE_21',\n",
    " 'ADATE_22',\n",
    " 'ADATE_23',\n",
    " 'ADATE_24',\n",
    "                   # Below: Information about how many promotions donor has received\n",
    " 'CARDPROM',\n",
    " 'MAXADATE',\n",
    " 'NUMPROM',\n",
    " 'CARDPM12',\n",
    " 'NUMPRM12',\n",
    "                   # Below: Date the donation was received\n",
    " 'RDATE_3',\n",
    " 'RDATE_4',\n",
    " 'RDATE_5',\n",
    " 'RDATE_6',\n",
    " 'RDATE_7',\n",
    " 'RDATE_8',\n",
    " 'RDATE_9',\n",
    " 'RDATE_10',\n",
    " 'RDATE_11',\n",
    " 'RDATE_12',\n",
    " 'RDATE_13',\n",
    " 'RDATE_14',\n",
    " 'RDATE_15',\n",
    " 'RDATE_16',\n",
    " 'RDATE_17',\n",
    " 'RDATE_18',\n",
    " 'RDATE_19',\n",
    " 'RDATE_20',\n",
    " 'RDATE_21',\n",
    " 'RDATE_22',\n",
    " 'RDATE_23',\n",
    " 'RDATE_24',\n",
    "                   # Below: Dollar amount of the donation\n",
    " 'RAMNT_3',\n",
    " 'RAMNT_4',\n",
    " 'RAMNT_5',\n",
    " 'RAMNT_6',\n",
    " 'RAMNT_7',\n",
    " 'RAMNT_8',\n",
    " 'RAMNT_9',\n",
    " 'RAMNT_10',\n",
    " 'RAMNT_11',\n",
    " 'RAMNT_12',\n",
    " 'RAMNT_13',\n",
    " 'RAMNT_14',\n",
    " 'RAMNT_15',\n",
    " 'RAMNT_16',\n",
    " 'RAMNT_17',\n",
    " 'RAMNT_18',\n",
    " 'RAMNT_19',\n",
    " 'RAMNT_20',\n",
    " 'RAMNT_21',\n",
    " 'RAMNT_22',\n",
    " 'RAMNT_23',\n",
    " 'RAMNT_24',\n",
    "                   # Below: Summary variables for this donor\n",
    " 'RAMNTALL',\n",
    " 'NGIFTALL',\n",
    " 'CARDGIFT',\n",
    " 'MINRAMNT',\n",
    " 'MINRDATE',\n",
    " 'MAXRAMNT',\n",
    " 'MAXRDATE',\n",
    " 'LASTGIFT',\n",
    " 'LASTDATE',\n",
    " 'FISTDATE',\n",
    " 'NEXTDATE',\n",
    " 'TIMELAG',\n",
    " 'AVGGIFT']\n",
    "\n",
    "print('Number of metric features:', len(metric_features))\n",
    "\n",
    "# Save this oroginal metric features list\n",
    "metric_features_orig = metric_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-metric features: 77\n"
     ]
    }
   ],
   "source": [
    "# Create a list with the non metrics features by excluding the metric ones\n",
    "non_metric_features = donors.columns.drop(metric_features).to_list()\n",
    "\n",
    "print('Number of non-metric features:', len(non_metric_features))\n",
    "\n",
    "# Save this oroginal metric features list\n",
    "non_metric_features_orig = non_metric_features.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treat features where \" \" (space) carries a meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAILCODE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' ', 'B'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = 'MAILCODE'\n",
    "pd.unique(donors[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Address is OK', 'Bad Address'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors[feature].replace(\" \", \"Address is OK\", inplace=True)\n",
    "donors[feature].replace(\"B\", \"Bad Address\", inplace=True)\n",
    "pd.unique(donors[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOEXCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', 'X', 0, 1, ' '], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = 'NOEXCH'\n",
    "pd.unique(donors[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['can be exchanged', 'do not exchange'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors[feature].replace(\" \", \"can be exchanged\", inplace=True)\n",
    "donors[feature].replace(\"X\", \"do not exchange\", inplace=True)\n",
    "# Assumption: 1 = do not exchange, 0 = can be exchanged (Makes sense because of the variable name)\n",
    "donors[feature].replace('0', \"can be exchanged\", inplace=True)\n",
    "donors[feature].replace('1', \"do not exchange\", inplace=True)\n",
    "donors[feature].replace(0, \"can be exchanged\", inplace=True)\n",
    "donors[feature].replace(1, \"do not exchange\", inplace=True)\n",
    "pd.unique(donors[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECINHSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' ', 'X'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = 'RECINHSE'\n",
    "pd.unique(donors[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not an In House Record',\n",
       "       \"Donor has given to PVA's In House program\"], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors[feature].replace(\" \", \"Not an In House Record\", inplace=True)\n",
    "donors[feature].replace(\"X\", \"Donor has given to PVA's In House program\", inplace=True)\n",
    "pd.unique(donors[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECP3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' ', 'X'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = 'RECP3'\n",
    "pd.unique(donors[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not a P3 Record', \"Donor has given to PVA's P3 program\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors[feature].replace(\" \", \"Not a P3 Record\", inplace=True)\n",
    "donors[feature].replace(\"X\", \"Donor has given to PVA's P3 program\", inplace=True)\n",
    "pd.unique(donors[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECPGVG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' ', 'X'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = 'RECPGVG'\n",
    "pd.unique(donors[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not a Planned Giving Record', 'Planned Giving Record'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors[feature].replace(\" \", \"Not a Planned Giving Record\", inplace=True)\n",
    "donors[feature].replace(\"X\", \"Planned Giving Record\", inplace=True)\n",
    "pd.unique(donors[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECSWEEP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' ', 'X'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = 'RECSWEEP'\n",
    "pd.unique(donors[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not a Sweepstakes Record', 'Sweepstakes Record'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors[feature].replace(\" \", \"Not a Sweepstakes Record\", inplace=True)\n",
    "donors[feature].replace(\"X\", \"Sweepstakes Record\", inplace=True)\n",
    "pd.unique(donors[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAJOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' ', 'X'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = 'MAJOR'\n",
    "pd.unique(donors[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not a Major Donor', 'Major Donor'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors[feature].replace(\" \", \"Not a Major Donor\", inplace=True)\n",
    "donors[feature].replace(\"X\", \"Major Donor\", inplace=True)\n",
    "pd.unique(donors[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asses existance of nan values and duplictes and deal with empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how many duplicated observations exist\n",
    "donors.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOB         23883\n",
       "NUMCHLD     83026\n",
       "INCOME      21286\n",
       "WEALTH1     44732\n",
       "MBCRAFT     52854\n",
       "            ...  \n",
       "RAMNT_24    77674\n",
       "FISTDATE        2\n",
       "NEXTDATE     9973\n",
       "TIMELAG      9973\n",
       "GEOCODE2      132\n",
       "Length: 92, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the variables that have missing values and their missing value counts\n",
    "missing_value_counts = donors.isna().sum()[donors.isna().sum()!=0]\n",
    "missing_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5158884"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the total number of nan values\n",
    "donors.isna().sum()[donors.isna().sum()!=0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \" \" by nans\n",
    "donors.replace(\" \", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8170773"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the total number of nan values once more\n",
    "donors.isna().sum()[donors.isna().sum()!=0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**About 3 million \" \" (spaces) were converted to nan.**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"\" by nans\n",
    "donors.replace(\"\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8170773"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the total number of nan values once more\n",
    "donors.isna().sum()[donors.isna().sum()!=0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**No additional nans added in this step.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess the percentage of missing values per feature and drop the features that have more than 40% mssing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ODATEDW     0.000000\n",
       "OSOURCE     0.972624\n",
       "TCODE       0.000000\n",
       "STATE       0.000000\n",
       "ZIP         0.000000\n",
       "              ...   \n",
       "RFA_2A      0.000000\n",
       "MDMAUD_R    0.000000\n",
       "MDMAUD_F    0.000000\n",
       "MDMAUD_A    0.000000\n",
       "GEOCODE2    0.334339\n",
       "Length: 475, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty list\n",
    "nan_percentage_list = []\n",
    "\n",
    "# Loop over the list of features and compute their percentage of nan values\n",
    "for feature in list(donors):\n",
    "    nan_percentage = len(donors[feature][donors[feature].isna()]) / len(donors[feature]) * 100\n",
    "    nan_percentage_list.append(nan_percentage)\n",
    "    \n",
    "# Create a look-up table\n",
    "nan_percentage_series = pd.Series(data=nan_percentage_list, index=list(donors))\n",
    "nan_percentage_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the features that have a lower amount of missing values\n",
    "lower_nan_percentage = nan_percentage_series[nan_percentage_series<=40].index.tolist()\n",
    "\n",
    "# Get a list of the features that have a higher amount of missing values\n",
    "higher_nan_percentage = nan_percentage_series[nan_percentage_series>40].index.tolist()\n",
    "\n",
    "# For report: Save the names of the features with the lower nan percentage in the variable \n",
    "# \"features_dropped_due_to_nans\"\n",
    "features_dropped_due_to_nans = higher_nan_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>MAILCODE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>RECINHSE</th>\n",
       "      <th>RECP3</th>\n",
       "      <th>...</th>\n",
       "      <th>AVGGIFT</th>\n",
       "      <th>CONTROLN</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>GEOCODE2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>GRI</td>\n",
       "      <td>0</td>\n",
       "      <td>IL</td>\n",
       "      <td>61081</td>\n",
       "      <td>Address is OK</td>\n",
       "      <td>1957-12-01</td>\n",
       "      <td>can be exchanged</td>\n",
       "      <td>Not an In House Record</td>\n",
       "      <td>Not a P3 Record</td>\n",
       "      <td>...</td>\n",
       "      <td>7.741935</td>\n",
       "      <td>95515</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>BOA</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>91326</td>\n",
       "      <td>Address is OK</td>\n",
       "      <td>1972-02-01</td>\n",
       "      <td>can be exchanged</td>\n",
       "      <td>Not an In House Record</td>\n",
       "      <td>Not a P3 Record</td>\n",
       "      <td>...</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>148535</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>G</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>AMH</td>\n",
       "      <td>1</td>\n",
       "      <td>NC</td>\n",
       "      <td>27017</td>\n",
       "      <td>Address is OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>can be exchanged</td>\n",
       "      <td>Not an In House Record</td>\n",
       "      <td>Not a P3 Record</td>\n",
       "      <td>...</td>\n",
       "      <td>7.481481</td>\n",
       "      <td>15078</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>BRY</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>95953</td>\n",
       "      <td>Address is OK</td>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>can be exchanged</td>\n",
       "      <td>Not an In House Record</td>\n",
       "      <td>Not a P3 Record</td>\n",
       "      <td>...</td>\n",
       "      <td>6.812500</td>\n",
       "      <td>172556</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FL</td>\n",
       "      <td>33176</td>\n",
       "      <td>Address is OK</td>\n",
       "      <td>1940-01-01</td>\n",
       "      <td>can be exchanged</td>\n",
       "      <td>Donor has given to PVA's In House program</td>\n",
       "      <td>Donor has given to PVA's P3 program</td>\n",
       "      <td>...</td>\n",
       "      <td>6.864865</td>\n",
       "      <td>7112</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95407</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>ASE</td>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>99504</td>\n",
       "      <td>Address is OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>can be exchanged</td>\n",
       "      <td>Not an In House Record</td>\n",
       "      <td>Not a P3 Record</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>184568</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95408</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>DCD</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>77379</td>\n",
       "      <td>Address is OK</td>\n",
       "      <td>1970-01-01</td>\n",
       "      <td>can be exchanged</td>\n",
       "      <td>Not an In House Record</td>\n",
       "      <td>Not a P3 Record</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>122706</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95409</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>MBC</td>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "      <td>48910</td>\n",
       "      <td>Address is OK</td>\n",
       "      <td>1958-01-01</td>\n",
       "      <td>can be exchanged</td>\n",
       "      <td>Not an In House Record</td>\n",
       "      <td>Donor has given to PVA's P3 program</td>\n",
       "      <td>...</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>189641</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95410</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>PRV</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>91320</td>\n",
       "      <td>Address is OK</td>\n",
       "      <td>1960-05-01</td>\n",
       "      <td>can be exchanged</td>\n",
       "      <td>Donor has given to PVA's In House program</td>\n",
       "      <td>Not a P3 Record</td>\n",
       "      <td>...</td>\n",
       "      <td>12.146341</td>\n",
       "      <td>4693</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95411</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>MCC</td>\n",
       "      <td>2</td>\n",
       "      <td>NC</td>\n",
       "      <td>28409</td>\n",
       "      <td>Address is OK</td>\n",
       "      <td>1938-01-01</td>\n",
       "      <td>can be exchanged</td>\n",
       "      <td>Donor has given to PVA's In House program</td>\n",
       "      <td>Not a P3 Record</td>\n",
       "      <td>...</td>\n",
       "      <td>96.794872</td>\n",
       "      <td>185114</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95412 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ODATEDW OSOURCE  TCODE STATE    ZIP       MAILCODE         DOB  \\\n",
       "0      2009-01-01     GRI      0    IL  61081  Address is OK  1957-12-01   \n",
       "1      2014-01-01     BOA      1    CA  91326  Address is OK  1972-02-01   \n",
       "2      2010-01-01     AMH      1    NC  27017  Address is OK         NaN   \n",
       "3      2007-01-01     BRY      0    CA  95953  Address is OK  1948-01-01   \n",
       "4      2006-01-01     NaN      0    FL  33176  Address is OK  1940-01-01   \n",
       "...           ...     ...    ...   ...    ...            ...         ...   \n",
       "95407  2016-01-01     ASE      1    AK  99504  Address is OK         NaN   \n",
       "95408  2016-01-01     DCD      1    TX  77379  Address is OK  1970-01-01   \n",
       "95409  2015-01-01     MBC      1    MI  48910  Address is OK  1958-01-01   \n",
       "95410  2006-01-01     PRV      0    CA  91320  Address is OK  1960-05-01   \n",
       "95411  2008-01-01     MCC      2    NC  28409  Address is OK  1938-01-01   \n",
       "\n",
       "                 NOEXCH                                   RECINHSE  \\\n",
       "0      can be exchanged                     Not an In House Record   \n",
       "1      can be exchanged                     Not an In House Record   \n",
       "2      can be exchanged                     Not an In House Record   \n",
       "3      can be exchanged                     Not an In House Record   \n",
       "4      can be exchanged  Donor has given to PVA's In House program   \n",
       "...                 ...                                        ...   \n",
       "95407  can be exchanged                     Not an In House Record   \n",
       "95408  can be exchanged                     Not an In House Record   \n",
       "95409  can be exchanged                     Not an In House Record   \n",
       "95410  can be exchanged  Donor has given to PVA's In House program   \n",
       "95411  can be exchanged  Donor has given to PVA's In House program   \n",
       "\n",
       "                                     RECP3  ...    AVGGIFT CONTROLN HPHONE_D  \\\n",
       "0                          Not a P3 Record  ...   7.741935    95515        0   \n",
       "1                          Not a P3 Record  ...  15.666667   148535        0   \n",
       "2                          Not a P3 Record  ...   7.481481    15078        1   \n",
       "3                          Not a P3 Record  ...   6.812500   172556        1   \n",
       "4      Donor has given to PVA's P3 program  ...   6.864865     7112        1   \n",
       "...                                    ...  ...        ...      ...      ...   \n",
       "95407                      Not a P3 Record  ...  25.000000   184568        0   \n",
       "95408                      Not a P3 Record  ...  20.000000   122706        1   \n",
       "95409  Donor has given to PVA's P3 program  ...   8.285714   189641        1   \n",
       "95410                      Not a P3 Record  ...  12.146341     4693        1   \n",
       "95411                      Not a P3 Record  ...  96.794872   185114        1   \n",
       "\n",
       "      RFA_2R RFA_2F  RFA_2A MDMAUD_R  MDMAUD_F MDMAUD_A  GEOCODE2  \n",
       "0          L      4       E        X         X        X         C  \n",
       "1          L      2       G        X         X        X         A  \n",
       "2          L      4       E        X         X        X         C  \n",
       "3          L      4       E        X         X        X         C  \n",
       "4          L      2       F        X         X        X         A  \n",
       "...      ...    ...     ...      ...       ...      ...       ...  \n",
       "95407      L      1       G        X         X        X         C  \n",
       "95408      L      1       F        X         X        X         A  \n",
       "95409      L      3       E        X         X        X         B  \n",
       "95410      L      4       F        X         X        X         A  \n",
       "95411      L      1       G        C         1        C         C  \n",
       "\n",
       "[95412 rows x 378 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors_1 = donors[lower_nan_percentage]\n",
    "donors_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accept the changes\n",
    "donors = donors_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_features(original_order, shuffled):\n",
    "    ordered = []\n",
    "    for feature in original_order:\n",
    "        if feature in shuffled:\n",
    "            ordered.append(feature)\n",
    "    return ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of metric features before removal: 398\n",
      "Number of metric features afer removal: 331\n"
     ]
    }
   ],
   "source": [
    "# Update 'metric_features' list\n",
    "\n",
    "# Print the number of metric features before the removal\n",
    "print('Number of metric features before removal:', len(metric_features))\n",
    "\n",
    "# Get the features that are metric features and still exist in our dataset\n",
    "metric_features = list(set(metric_features).intersection(set(donors)))\n",
    "\n",
    "# And sort them according to our original order\n",
    "metric_features = sort_features(metric_features_orig, metric_features)\n",
    "\n",
    "# Print the number of metric features after the removal\n",
    "print('Number of metric features afer removal:', len(metric_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-metric features before removal: 77\n",
      "Number of non-metric features afer removal: 47\n"
     ]
    }
   ],
   "source": [
    "# Update 'non_metric_features' list\n",
    "\n",
    "# Print the number of metric features before the removal\n",
    "print('Number of non-metric features before removal:', len(non_metric_features))\n",
    "\n",
    "# Get the features that are metric features and still exist in our dataset\n",
    "non_metric_features = list(set(non_metric_features).intersection(set(donors)))\n",
    "\n",
    "# And sort them according to our original order\n",
    "non_metric_features = sort_features(non_metric_features_orig, non_metric_features)\n",
    "\n",
    "# Print the number of metric features after the removal\n",
    "print('Number of non-metric features afer removal:', len(non_metric_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770663"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the total number of nan values once more\n",
    "donors.isna().sum()[donors.isna().sum()!=0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Before: About 8 million nans. Now: Less than 1 million nans.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform columns containing dates to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_string_to_date_if_not_nan(x):\n",
    "    \"\"\"This function checks if something is a string, and if so, converts it into a datetime object\"\"\"\n",
    "    # If it's not a nan, but a string\n",
    "    if type(x)==str:\n",
    "        x = datetime.datetime.strptime(x, '%Y-%m-%d').date()\n",
    "    # if it's a nan, change to NaT\n",
    "    # else:\n",
    "    #     x = pd.NaT\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for converting series containing strings to series containing datetime objects\n",
    "def series_string_to_date(series):\n",
    "    \"\"\"This function turns a pandas series that consists of String values into a pandas series containing \n",
    "    datetime objects\"\"\"\n",
    "    series_datetime = series.map(lambda x: series_string_to_date_if_not_nan(x))\n",
    "    return series_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_string_col_by_date_col(df, colname):\n",
    "    \"\"\"This function uses 'series_string_to_date' for replacing a string column by a datetime object column\"\"\"\n",
    "    df[colname] = series_string_to_date(df[colname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for checking data types\n",
    "if False:\n",
    "    labels_types = pd.DataFrame({'Labels':list(donors), 'Data types':list(donors.dtypes)})\n",
    "    labels_types[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labels who's columns should be changed to datetime\n",
    "date_features = [\n",
    "    'ODATEDW',\n",
    "    'DOB',\n",
    "    'ADATE_2',\n",
    "    'ADATE_3',\n",
    "    'ADATE_4',\n",
    "    'ADATE_5',\n",
    "    'ADATE_6',\n",
    "    'ADATE_7',\n",
    "    'ADATE_8',\n",
    "    'ADATE_9',\n",
    "    'ADATE_10',\n",
    "    'ADATE_11',\n",
    "    'ADATE_12',\n",
    "    'ADATE_13',\n",
    "    'ADATE_14',\n",
    "    'ADATE_15',\n",
    "    'ADATE_16',\n",
    "    'ADATE_17',\n",
    "    'ADATE_18',\n",
    "    'ADATE_19',\n",
    "    'ADATE_20',\n",
    "    'ADATE_21',\n",
    "    'ADATE_22',\n",
    "    'ADATE_23',\n",
    "    'ADATE_24',\n",
    "    'MAXADATE',\n",
    "    'RDATE_3',\n",
    "    'RDATE_4',\n",
    "    'RDATE_5',\n",
    "    'RDATE_6',\n",
    "    'RDATE_7',\n",
    "    'RDATE_8',\n",
    "    'RDATE_9',\n",
    "    'RDATE_10',\n",
    "    'RDATE_11',\n",
    "    'RDATE_12',\n",
    "    'RDATE_13',\n",
    "    'RDATE_14',\n",
    "    'RDATE_15',\n",
    "    'RDATE_16',\n",
    "    'RDATE_17',\n",
    "    'RDATE_18',\n",
    "    'RDATE_19',\n",
    "    'RDATE_20',\n",
    "    'RDATE_21',\n",
    "    'RDATE_22',\n",
    "    'RDATE_23',\n",
    "    'RDATE_24',\n",
    "    'MINRDATE',\n",
    "    'MAXRDATE',\n",
    "    'LASTDATE',\n",
    "    'FISTDATE',\n",
    "    'NEXTDATE',\n",
    "]\n",
    "\n",
    "# Save this original list of date features\n",
    "date_features_orig = date_features.copy()\n",
    "\n",
    "# Get the features that are date features and still exist in our dataset\n",
    "date_features = list(set(date_features).intersection(set(donors)))\n",
    "\n",
    "# And sort them according to our original order\n",
    "date_features = sort_features(date_features_orig, date_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for checking the existing datatypes in a given columns\n",
    "# This needs some work. Doesn't always work properly\n",
    "if False:\n",
    "    feature = 'NUMCHLD'\n",
    "    unique_types = set()\n",
    "    str_indices = []\n",
    "    float_indices = []\n",
    "    other_indices = []\n",
    "    for i in range(len(donors[feature])):\n",
    "        if type(donors[feature][i])==str:\n",
    "                str_indices.append(i)\n",
    "        if type(donors[feature][i])==float:\n",
    "                float_indices.append(i)\n",
    "        else:\n",
    "                other_indices.append(i)\n",
    "        unique_types.add(type(donors[feature][i]))\n",
    "    nans = donors[feature][float_indices]\n",
    "    strings = donors[feature][str_indices]\n",
    "    print('Strings:', strings)\n",
    "    print('Floats (can be NaNs):', nans)\n",
    "    print('Contains the following data types:', unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the functions defined above to change all non-nan values of the columns in 'date_features' datetime objects\n",
    "for label_to_change in date_features:\n",
    "    replace_string_col_by_date_col(donors, label_to_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n",
      "<class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "# Check that it worked properly\n",
    "for i in range(len(date_features)):\n",
    "    print(type(donors[date_features[i]][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       23043 days\n",
       "1       17868 days\n",
       "2              NaT\n",
       "3       26665 days\n",
       "4       29587 days\n",
       "           ...    \n",
       "95407          NaT\n",
       "95408   18629 days\n",
       "95409   23012 days\n",
       "95410   22161 days\n",
       "95411   30317 days\n",
       "Name: DOB, Length: 95412, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if time calculations work properly with these columns\n",
    "now = date.today()\n",
    "now - donors['DOB']\n",
    "# Seems to work well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pandas-profiling report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    \n",
    "    now_string = str(datetime.datetime.now())\n",
    "\n",
    "    profile = ProfileReport(\n",
    "        donors, \n",
    "        title='Donors Data',\n",
    "        correlations={\n",
    "            \"pearson\": {\"calculate\": True},\n",
    "            \"spearman\": {\"calculate\": True},\n",
    "            \"kendall\": {\"calculate\": False},\n",
    "            \"phi_k\": {\"calculate\": False},\n",
    "            \"cramers\": {\"calculate\": False},\n",
    "        },\n",
    "        minimal = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    \n",
    "    folder_path = os.path.join('pandas-profiling', now_string)\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    profile.to_file(os.path.join(folder_path, \"pandas_profiling.html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from \"lab04_data_visualization\" (Data Mining)\n",
    "def single_hist(feature, savefig, *n_of_bins):\n",
    "    \"\"\"This function takes feature name and produces a visualisation of the histogram of the respective feature\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(15,10))\n",
    "    \n",
    "    # Single Metric Variable Histogram\n",
    "    if len(n_of_bins)==0:\n",
    "        print('Number of bins: Automatic')\n",
    "        plt.hist(donors[feature])\n",
    "    else:\n",
    "        print('Number of bins:', n_of_bins[0])\n",
    "        plt.hist(donors[feature], bins = n_of_bins[0])\n",
    "    plt.title(feature, y=-0.1)\n",
    "    \n",
    "    if savefig:\n",
    "        # Save figure and include time stamp in filename\n",
    "        now_string = str(datetime.datetime.now())[0:19].replace(':', '-').replace(' ', '_')\n",
    "        folder_path = os.path.join('figures')\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        filename = now_string + '_' + feature + '_single_histogram.png'\n",
    "        plt.savefig(os.path.join(folder_path, filename), dpi=200)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from \"lab04_data_visualization\" (Data Mining)\n",
    "\n",
    "def many_hists(features, savefig, *n_of_bins):\n",
    "    \"\"\"This function takes a list of features and optionally a number of bins and creates histograms of these\n",
    "    features.\"\"\"\n",
    "    \n",
    "    # All Numeric Variables' Histograms in one figure\n",
    "    sns.set()\n",
    "\n",
    "    # Prepare figure. Create individual axes where each histogram will be placed\n",
    "    fig, axes = plt.subplots(2, ceil(len(features) / 2), figsize=(20, 11))\n",
    "\n",
    "    # Plot data\n",
    "    # Iterate across axes objects and associate each histogram (hint: use the ax.hist() instead of plt.hist()):\n",
    "    for ax, feat in zip(axes.flatten(), features): # Notice the zip() function and flatten() method\n",
    "        \n",
    "        if len(n_of_bins)==0:\n",
    "            \n",
    "            if feat == features[0]:\n",
    "                print('Number of bins: Automatic')\n",
    "            \n",
    "            ax.hist(donors[feat])\n",
    "            \n",
    "        else:\n",
    "            if feat == features[0]:\n",
    "                print('Number of bins:', n_of_bins[0])\n",
    "            ax.hist(donors[feat], bins = n_of_bins[0])\n",
    "            \n",
    "        ax.set_title(feat, y=-0.13)\n",
    "\n",
    "    # Layout\n",
    "    # Add a centered title to the figure:\n",
    "    title = \"Numeric Variables' Histograms\"\n",
    "\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    if savefig:\n",
    "        # Save figure and include time stamp, the feature names and the method in the filename\n",
    "        now_string = str(datetime.datetime.now())[0:19].replace(':', '-').replace(' ', '_')\n",
    "        folder_path = os.path.join('figures')\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        filename = now_string + '_' +  '-'.join(features) + '_histograms_' + str(n_of_bins[0]) + '_bins.png'\n",
    "        plt.savefig(os.path.join(folder_path, filename), dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_value(feature, value):\n",
    "    \"\"\"This function takes a feature name and a value and turns all elements of the respective column with this value\n",
    "    into nans.\"\"\"\n",
    "    series = donors[feature].copy()\n",
    "    series[series==value]=np.nan\n",
    "    donors[feature] = series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from \"lab04_data_visualization\" (Data Mining)\n",
    "\n",
    "def corr_matrix_visualisation(features, savefig, method):\n",
    "    \"\"\"This function takes a list of features and created a visualisation of their correlation matrix.\"\"\"\n",
    "    \n",
    "    # Prepare figure\n",
    "    fig = plt.figure(figsize=(25, 15))\n",
    "\n",
    "    # Obtain correlation matrix. Round the values to 4 decimal cases. Use the DataFrame corr() and round() method.\n",
    "    corr = np.round(donors[features].corr(method=method), decimals=4)\n",
    "\n",
    "    # Build annotation matrix (values above |bound| will appear annotated in the plot)\n",
    "    bound = 0\n",
    "    mask_annot = np.absolute(corr.values) >= bound\n",
    "    annot = np.where(mask_annot, corr.values, np.full(corr.shape,\"\")) # Try to understand what this np.where() does\n",
    "\n",
    "    # Plot heatmap of the correlation matrix\n",
    "    sns.heatmap(data=corr, annot=annot, cmap=sns.diverging_palette(220, 10, as_cmap=True), \n",
    "                fmt='s', vmin=-1, vmax=1, center=0, square=True, linewidths=.5)\n",
    "\n",
    "    # Layout\n",
    "    fig.subplots_adjust(top=0.95)\n",
    "    fig.suptitle('Correlation Matrix' + ' (' + method + ')', fontsize=20)\n",
    "\n",
    "    if savefig:\n",
    "        # Save figure and include time stamp, the feature names and the method in the filename\n",
    "        now_string = str(datetime.datetime.now())[0:19].replace(':', '-').replace(' ', '_')\n",
    "        folder_path = os.path.join('figures')\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        filename = now_string + '_' +  '-'.join(features) + '_' + method + '_corr_matrix.png'\n",
    "        plt.savefig(os.path.join(folder_path, filename), dpi=200)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniques_nans_variance(feature):\n",
    "    \"\"\"This function takes the name of a feature and prints its unique values, its percentage of missing values and\n",
    "    its standard deviation. Then (optionally) it returns the respective column so it is displayed as output.\"\"\"\n",
    "    \n",
    "    print('Unique values:')\n",
    "    unique = pd.unique(donors[feature])\n",
    "    unique.sort()\n",
    "    print(unique)\n",
    "    print()\n",
    "    \n",
    "    print('Percentage of missing values:')\n",
    "    print(round(len(donors[feature][donors[feature].isna()])/len(donors[feature]), 4), '%')\n",
    "    print()\n",
    "    \n",
    "    print('Minimum value:', donors[feature].min(), '- Share:', \\\n",
    "          round(((len(donors[feature][donors[feature]==donors[feature].min()])) / len(donors[feature])), 6) * 100, '%')\n",
    "    \n",
    "    print('Maximum value:', donors[feature].max(), '- Share:', \\\n",
    "          round(((len(donors[feature][donors[feature]==donors[feature].max()])) / len(donors[feature])), 6) * 100, '%')\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        print('Sample standard deviation:', round(donors[feature].std(), 4))\n",
    "    except:\n",
    "        print(\"Couldn't compute a variance\")\n",
    "        \n",
    "    # return donors[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_nans_variance_min_max(features):\n",
    "    \"\"\"This function takes a list of features and computes their percentages of missing values, their sample\n",
    "    standard deviations, their Minima and Maxima and the percentage of how much the minima and maxima are in\n",
    "    this feature. Then it saves all this in a DataFrame which it returns.\"\"\"\n",
    "    nans = []\n",
    "    st_devs = []\n",
    "    mins = []\n",
    "    min_shares = []\n",
    "    maxs = []\n",
    "    max_shares = []\n",
    "    for feature in features:\n",
    "        nans.append(round(len(donors[feature][donors[feature].isna()])/len(donors[feature]), 4))\n",
    "        st_devs.append(round(donors[feature].std(), 4))\n",
    "        mins.append(donors[feature].min())\n",
    "        min_shares.append(round(((len(donors[feature][donors[feature]==donors[feature].min()])) \\\n",
    "                                 / len(donors[feature])),6) * 100)\n",
    "        maxs.append(donors[feature].max())\n",
    "        max_shares.append(round(((len(donors[feature][donors[feature]==donors[feature].max()])) \\\n",
    "                                 / len(donors[feature])),6) * 100)\n",
    "    \n",
    "    df = pd.DataFrame(data = {'Missing values [%]': nans, 'Sample standard deviation [Unit of feature]': st_devs, 'Minimum [Unit of f.]': mins,\\\n",
    "                              'Share of Minimum [%]:': min_shares, 'Maximum [Unit of f.]': maxs, 'Share of Maximum [%]': max_shares},\\\n",
    "                      index = features)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def many_boxplots(features, savefig):\n",
    "    \n",
    "    # All Numeric Variables' Box Plots in one figure\n",
    "    sns.set()\n",
    "\n",
    "    # Prepare figure. Create individual axes where each box plot will be placed\n",
    "    fig, axes = plt.subplots(2, ceil(len(features) / 2), figsize=(20, 11))\n",
    "\n",
    "    # Plot data\n",
    "    # Iterate across axes objects and associate each box plot (hint: use the ax argument):\n",
    "    for ax, feat in zip(axes.flatten(), features): # Notice the zip() function and flatten() method\n",
    "        sns.boxplot(x=donors[feat], ax=ax)\n",
    "\n",
    "    # Layout\n",
    "    # Add a centered title to the figure:\n",
    "    title = \"Numeric Variables' Box Plots\"\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    if savefig:\n",
    "        # Save figure and include time stamp, the feature names and the method in the filename\n",
    "        now_string = str(datetime.datetime.now())[0:19].replace(':', '-').replace(' ', '_')\n",
    "        folder_path = os.path.join('figures')\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        filename = now_string + '_' +  '-'.join(features) + '_boxplots.png'\n",
    "        plt.savefig(os.path.join(folder_path, filename), dpi=200)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from \"lab04_data_visualization\" (Data Mining)\n",
    "\n",
    "def pairwise(features, flag_kdeplot):\n",
    "    \"\"\"This function takes a list of features and creates their pairwise scatterplots and each feature's histogram.\n",
    "    If 'flag_kdeplot' = True, a Kernel Dnsity Etimation plot will be added.\"\"\"\n",
    "    \n",
    "    if flag_kdeplot:\n",
    "        print('Plotting with Kernel Density Estimation. This will increase computation time immensely.')\n",
    "    else:\n",
    "        print('Plotting without Kernel Density Estimation.')\n",
    "    \n",
    "    # Pairwise Relationship of Numerical Variables\n",
    "    sns.set()\n",
    "\n",
    "    # Setting pairplot\n",
    "    g = sns.pairplot(donors[features], diag_kind=\"hist\", corner=True)\n",
    "    \n",
    "    if flag_kdeplot:\n",
    "        g.map_lower(sns.kdeplot, levels=4, color=\".2\")\n",
    "\n",
    "    # Layout\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    plt.suptitle(\"Pairwise Relationship of Numerical Variables\", fontsize=20)\n",
    "\n",
    "    # Save figure and include time stamp, the feature names and the method in the filename\n",
    "    now_string = str(datetime.datetime.now())[0:19].replace(':', '-').replace(' ', '_')\n",
    "    folder_path = os.path.join('figures')\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    filename = now_string + '_' +  '-'.join(features) + '_pairwise_plots.png'\n",
    "    plt.savefig(os.path.join(folder_path, filename), dpi=200)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove value 0 from columns 'AGE901', 'AGE902', 'AGE903', 'AGE904', 'AGE905', 'AGE906','AGE907'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['AGE901', 'AGE902', 'AGE903', 'AGE904', 'AGE905', 'AGE906','AGE907']\n",
    "\n",
    "savefig = False\n",
    "switch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing values [%]</th>\n",
       "      <th>Sample standard deviation [Unit of feature]</th>\n",
       "      <th>Minimum [Unit of f.]</th>\n",
       "      <th>Share of Minimum [%]:</th>\n",
       "      <th>Maximum [Unit of f.]</th>\n",
       "      <th>Share of Maximum [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AGE901</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3356</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>84</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE902</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.2497</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>84</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE903</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.1091</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>84</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE904</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2612</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>84</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE905</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.9600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>84</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE906</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.8827</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>84</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE907</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3174</td>\n",
       "      <td>75</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Missing values [%]  Sample standard deviation [Unit of feature]  \\\n",
       "AGE901                 0.0                                       8.3356   \n",
       "AGE902                 0.0                                       8.2497   \n",
       "AGE903                 0.0                                       8.1091   \n",
       "AGE904                 0.0                                       7.2612   \n",
       "AGE905                 0.0                                       6.9600   \n",
       "AGE906                 0.0                                       6.8827   \n",
       "AGE907                 0.0                                       7.5153   \n",
       "\n",
       "        Minimum [Unit of f.]  Share of Minimum [%]:  Maximum [Unit of f.]  \\\n",
       "AGE901                     0                 0.8374                    84   \n",
       "AGE902                     0                 0.8374                    84   \n",
       "AGE903                     0                 0.8374                    84   \n",
       "AGE904                     0                 0.8374                    84   \n",
       "AGE905                     0                 0.8374                    84   \n",
       "AGE906                     0                 0.8374                    84   \n",
       "AGE907                     0                 1.3174                    75   \n",
       "\n",
       "        Share of Maximum [%]  \n",
       "AGE901                 0.001  \n",
       "AGE902                 0.001  \n",
       "AGE903                 0.001  \n",
       "AGE904                 0.001  \n",
       "AGE905                 0.001  \n",
       "AGE906                 0.001  \n",
       "AGE907                 0.001  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nans_variance_min_max(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**None of these features have missing values. All of them have suspiciously many zeros. Assume: Missing values were saved as zeros. Remove zeros.**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros with nans\n",
    "for feature in ['AGE901', 'AGE902', 'AGE903', 'AGE904', 'AGE905', 'AGE906','AGE907']:\n",
    "    remove_value(feature, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**After removing zeros:**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove value 0 from columns 'HHAGE1', 'AGEC6', 'HHAGE2', 'HHAGE3'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['HHAGE1', 'AGEC6', 'HHAGE2', 'HHAGE3']\n",
    "\n",
    "savefig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing values [%]</th>\n",
       "      <th>Sample standard deviation [Unit of feature]</th>\n",
       "      <th>Minimum [Unit of f.]</th>\n",
       "      <th>Share of Minimum [%]:</th>\n",
       "      <th>Maximum [Unit of f.]</th>\n",
       "      <th>Share of Maximum [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HHAGE1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0903</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGEC6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0038</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1120</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHAGE2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4415</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1622</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHAGE3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9639</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0806</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Missing values [%]  Sample standard deviation [Unit of feature]  \\\n",
       "HHAGE1                 0.0                                      13.0903   \n",
       "AGEC6                  0.0                                       6.0038   \n",
       "HHAGE2                 0.0                                       7.4415   \n",
       "HHAGE3                 0.0                                      12.9639   \n",
       "\n",
       "        Minimum [Unit of f.]  Share of Minimum [%]:  Maximum [Unit of f.]  \\\n",
       "HHAGE1                     0                 0.9705                    99   \n",
       "AGEC6                      0                 1.1120                    99   \n",
       "HHAGE2                     0                 2.1622                    99   \n",
       "HHAGE3                     0                 1.0806                    99   \n",
       "\n",
       "        Share of Maximum [%]  \n",
       "HHAGE1                0.0126  \n",
       "AGEC6                 0.0021  \n",
       "HHAGE2                0.0063  \n",
       "HHAGE3                0.0115  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nans_variance_min_max(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**None of these features have missing values. 'HHAGE1', 'AGEC6', 'HHAGE3' have many zeros in comparison to surrounding area in their histograms. Assume: Missing values were saved as zeros. Remove zeros from 'HHAGE1', 'AGEC6', 'HHAGE3'.**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros with nans\n",
    "for feature in ['HHAGE1', 'AGEC6', 'HHAGE3']:\n",
    "    remove_value(feature, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**After removing zeros:**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove value 0 from columns 'HHN1', 'HHN2', 'HHN3', 'HHN4', 'HHN5', 'HHN6' ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['HHN1', 'HHN2', 'HHN3', 'HHN4', 'HHN5', 'HHN6']\n",
    "\n",
    "savefig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing values [%]</th>\n",
       "      <th>Sample standard deviation [Unit of feature]</th>\n",
       "      <th>Minimum [Unit of f.]</th>\n",
       "      <th>Share of Minimum [%]:</th>\n",
       "      <th>Maximum [Unit of f.]</th>\n",
       "      <th>Share of Maximum [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HHN1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.7696</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHN2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.2325</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9035</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHN3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5385</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9464</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHN4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0592</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4306</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHN5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3828</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1685</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHN6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7930</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3400</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Missing values [%]  Sample standard deviation [Unit of feature]  \\\n",
       "HHN1                 0.0                                      11.7696   \n",
       "HHN2                 0.0                                       8.2325   \n",
       "HHN3                 0.0                                      14.5385   \n",
       "HHN4                 0.0                                      11.0592   \n",
       "HHN5                 0.0                                       6.3828   \n",
       "HHN6                 0.0                                       3.7930   \n",
       "\n",
       "      Minimum [Unit of f.]  Share of Minimum [%]:  Maximum [Unit of f.]  \\\n",
       "HHN1                     0                 0.9129                    99   \n",
       "HHN2                     0                 0.9035                    99   \n",
       "HHN3                     0                 0.9464                    99   \n",
       "HHN4                     0                 1.4306                    99   \n",
       "HHN5                     0                 2.1685                    99   \n",
       "HHN6                     0                 5.3400                    99   \n",
       "\n",
       "      Share of Maximum [%]  \n",
       "HHN1                0.0210  \n",
       "HHN2                0.0073  \n",
       "HHN3                0.0157  \n",
       "HHN4                0.0073  \n",
       "HHN5                0.0063  \n",
       "HHN6                0.0042  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nans_variance_min_max(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Justifiable to remove zeros from HHN1, HHN2, HHN3 and HHN4. Same reasoning as above.**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros with nans\n",
    "for feature in ['HHN1', 'HHN2', 'HHN3', 'HHN4']:\n",
    "    remove_value(feature, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**After removing zeros:**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove value 0 from columns 'HHP1', 'HHP2', 'HHN3', 'HHN4', 'HHD1', 'RHP3' ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'HHP1', # (\"Median Person Per Household\")\n",
    "    'HHP2', # (\"Average Person Per Household\")\n",
    "    'HHN3', # (\"Percent 3 or More Person Households\")\n",
    "    'HHN4', # (\"Percent 4 or More Person Households\")\n",
    "    'HHD1', # (\"Percent Households w/ Related Children\")\n",
    "    'RHP3' # (\"Median Number of Persons per Housing Unit\")\n",
    "]\n",
    "\n",
    "savefig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing values [%]</th>\n",
       "      <th>Sample standard deviation [Unit of feature]</th>\n",
       "      <th>Minimum [Unit of f.]</th>\n",
       "      <th>Share of Minimum [%]:</th>\n",
       "      <th>Maximum [Unit of f.]</th>\n",
       "      <th>Share of Maximum [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HHP1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>50.0412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8563</td>\n",
       "      <td>650.0</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHP2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>49.9018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8563</td>\n",
       "      <td>700.0</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHN3</th>\n",
       "      <td>0.0095</td>\n",
       "      <td>13.9929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1352</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHN4</th>\n",
       "      <td>0.0143</td>\n",
       "      <td>10.6967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHD1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.0351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3384</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RHP3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.5598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Missing values [%]  Sample standard deviation [Unit of feature]  \\\n",
       "HHP1              0.0000                                      50.0412   \n",
       "HHP2              0.0000                                      49.9018   \n",
       "HHN3              0.0095                                      13.9929   \n",
       "HHN4              0.0143                                      10.6967   \n",
       "HHD1              0.0000                                      13.0351   \n",
       "RHP3              0.0000                                       2.5598   \n",
       "\n",
       "      Minimum [Unit of f.]  Share of Minimum [%]:  Maximum [Unit of f.]  \\\n",
       "HHP1                   0.0                 0.8563                 650.0   \n",
       "HHP2                   0.0                 0.8563                 700.0   \n",
       "HHN3                   1.0                 0.1352                  99.0   \n",
       "HHN4                   1.0                 0.4025                  99.0   \n",
       "HHD1                   0.0                 1.3384                  99.0   \n",
       "RHP3                   0.0                 0.8374                  61.0   \n",
       "\n",
       "      Share of Maximum [%]  \n",
       "HHP1                0.0042  \n",
       "HHP2                0.0042  \n",
       "HHN3                0.0157  \n",
       "HHN4                0.0073  \n",
       "HHD1                0.0105  \n",
       "RHP3                0.0042  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nans_variance_min_max(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Justifiable to remove zeros from HHP1, HHP2, HHD1 and RHP3. Same reasoning as above.**<span>\n",
    "    \n",
    "<span style=\"color:red\">**Remark: RHP3 looks odd. Let's consider removing it. (Will be removed in the next step.)**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros with nans\n",
    "for feature in ['HHP1', 'HHP2', 'HHD1', 'RHP3']:\n",
    "    remove_value(feature, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**After removing zeros:**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove value 0 from columns  'RP1', 'RP2', 'RP3', 'RP4', 'HV4' ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'RP1', # (\"Percent Renters Paying >= $500 per Month\")\n",
    "    'RP2', # (\"Percent Renters Paying >= $400 per Month\")\n",
    "    'RP3', # (\"Percent Renters Paying >= $300 per Month\")\n",
    "    'RP4', # (\"Percent Renters Paying >= $200 per Month\")\n",
    "    'HV4', # (\"Average Contract Rent in hundreds\")\n",
    "]\n",
    "\n",
    "savefig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing values [%]</th>\n",
       "      <th>Sample standard deviation [Unit of feature]</th>\n",
       "      <th>Minimum [Unit of f.]</th>\n",
       "      <th>Share of Minimum [%]:</th>\n",
       "      <th>Maximum [Unit of f.]</th>\n",
       "      <th>Share of Maximum [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RP1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>32.1951</td>\n",
       "      <td>0</td>\n",
       "      <td>16.8134</td>\n",
       "      <td>99</td>\n",
       "      <td>0.8165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RP2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>34.9308</td>\n",
       "      <td>0</td>\n",
       "      <td>6.7947</td>\n",
       "      <td>99</td>\n",
       "      <td>1.6256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RP3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>32.8939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8059</td>\n",
       "      <td>99</td>\n",
       "      <td>4.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RP4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.2759</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0093</td>\n",
       "      <td>99</td>\n",
       "      <td>8.0535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HV4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2444</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2881</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Missing values [%]  Sample standard deviation [Unit of feature]  \\\n",
       "RP1                 0.0                                      32.1951   \n",
       "RP2                 0.0                                      34.9308   \n",
       "RP3                 0.0                                      32.8939   \n",
       "RP4                 0.0                                      24.2759   \n",
       "HV4                 0.0                                       2.2444   \n",
       "\n",
       "     Minimum [Unit of f.]  Share of Minimum [%]:  Maximum [Unit of f.]  \\\n",
       "RP1                     0                16.8134                    99   \n",
       "RP2                     0                 6.7947                    99   \n",
       "RP3                     0                 1.8059                    99   \n",
       "RP4                     0                 1.0093                    99   \n",
       "HV4                     0                 1.2881                    13   \n",
       "\n",
       "     Share of Maximum [%]  \n",
       "RP1                0.8165  \n",
       "RP2                1.6256  \n",
       "RP3                4.0100  \n",
       "RP4                8.0535  \n",
       "HV4                0.0472  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nans_variance_min_max(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Justifiable to remove zeros from RP3, RP4. Same reasoning as above.**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros with nans\n",
    "for feature in ['RP3', 'RP4']:\n",
    "    remove_value(feature, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**After removing zeros:**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove value 0 from columns 'IC1', 'IC2', 'IC3', 'IC4', 'IC5' ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'IC1', # (\"Median Household Income in hundreds\")\n",
    "    'IC2', # (\"Median Family Income in hundreds\")\n",
    "    'IC3', # (\"Average Household Income in hundreds\")\n",
    "    'IC4', # (\"Average Family Income in hundreds\")\n",
    "    'IC5', #(\"Per Capita Income\")\n",
    "]\n",
    "\n",
    "savefig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing values [%]</th>\n",
       "      <th>Sample standard deviation [Unit of feature]</th>\n",
       "      <th>Minimum [Unit of f.]</th>\n",
       "      <th>Share of Minimum [%]:</th>\n",
       "      <th>Maximum [Unit of f.]</th>\n",
       "      <th>Share of Maximum [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IC1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>162.8833</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9202</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.0975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>173.6146</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9726</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>161.2707</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9202</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>171.6433</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9726</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.0031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8563.6468</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9014</td>\n",
       "      <td>174523</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Missing values [%]  Sample standard deviation [Unit of feature]  \\\n",
       "IC1                 0.0                                     162.8833   \n",
       "IC2                 0.0                                     173.6146   \n",
       "IC3                 0.0                                     161.2707   \n",
       "IC4                 0.0                                     171.6433   \n",
       "IC5                 0.0                                    8563.6468   \n",
       "\n",
       "     Minimum [Unit of f.]  Share of Minimum [%]:  Maximum [Unit of f.]  \\\n",
       "IC1                     0                 0.9202                  1500   \n",
       "IC2                     0                 0.9726                  1500   \n",
       "IC3                     0                 0.9202                  1500   \n",
       "IC4                     0                 0.9726                  1500   \n",
       "IC5                     0                 0.9014                174523   \n",
       "\n",
       "     Share of Maximum [%]  \n",
       "IC1                0.0975  \n",
       "IC2                0.1499  \n",
       "IC3                0.0021  \n",
       "IC4                0.0031  \n",
       "IC5                0.0010  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nans_variance_min_max(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Justifiable to remove zeros from all of them. Same reasoning as above.**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros with nans\n",
    "for feature in ['IC1','IC2','IC3','IC4','IC5']: \n",
    "    remove_value(feature, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**After removing zeros:**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove value 0 from columns 'IC6', ... , 'IC23' ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "households = [\n",
    "    'IC6', # (\"Percent Households w/ Income < $15,000\")\n",
    "    'IC7', # (\"Percent Households w/ Income $15,000 - $24,999\")\n",
    "    'IC8', # (\"Percent Households w/ Income $25,000 - $34,999\")\n",
    "    'IC9', # (\"Percent Households w/ Income $35,000 - $49,999\")\n",
    "    'IC10', # (\"Percent Households w/ Income $50,000 - $74,999\")\n",
    "    'IC11', # (\"Percent Households w/ Income $75,000 - $99,999\")\n",
    "    'IC12', # (\"Percent Households w/ Income $100,000 - $124,999\")\n",
    "    'IC13', # (\"Percent Households w/ Income $125,000 - $149,999\")\n",
    "    'IC14', # (\"Percent Households w/ Income >= $150,000\")\n",
    "]\n",
    "\n",
    "families = [\n",
    "    'IC15', # (\"Percent Families w/ Income < $15,000\")\n",
    "    'IC16', # (\"Percent Families w/ Income $15,000 - $24,999\")\n",
    "    'IC17', # (\"Percent Families w/ Income $25,000 - 34,999\")\n",
    "    'IC18', # (\"Percent Families w/ Income $35,000 - $49,999\")\n",
    "    'IC19', # (\"Percent Families w/ Income $50,000 - $74,999\")\n",
    "    'IC20', # (\"Percent Families w/ Income $75,000 - $99,999\")\n",
    "    'IC21', # (\"Percent Families w/ Income $100,000 - $124,999\")\n",
    "    'IC22', # (\"Percent Families w/ Income $125,000 - $149,999\")\n",
    "    'IC23' # (\"Percent Families w/ Income >= $150,000\")\n",
    "]\n",
    "\n",
    "features = households + families\n",
    "\n",
    "savefig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing values [%]</th>\n",
       "      <th>Sample standard deviation [Unit of feature]</th>\n",
       "      <th>Minimum [Unit of f.]</th>\n",
       "      <th>Share of Minimum [%]:</th>\n",
       "      <th>Maximum [Unit of f.]</th>\n",
       "      <th>Share of Maximum [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IC6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5106</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2817</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9473</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2784</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6581</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4381</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4925</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6860</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6464</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8353</td>\n",
       "      <td>0</td>\n",
       "      <td>15.2622</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3463</td>\n",
       "      <td>0</td>\n",
       "      <td>40.5546</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9231</td>\n",
       "      <td>0</td>\n",
       "      <td>64.3776</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6407</td>\n",
       "      <td>0</td>\n",
       "      <td>54.6787</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.3411</td>\n",
       "      <td>0</td>\n",
       "      <td>5.8473</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.1708</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6406</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5615</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.4727</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0039</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.6442</td>\n",
       "      <td>0</td>\n",
       "      <td>3.3277</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.6662</td>\n",
       "      <td>0</td>\n",
       "      <td>16.8993</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9072</td>\n",
       "      <td>0</td>\n",
       "      <td>41.4707</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3217</td>\n",
       "      <td>0</td>\n",
       "      <td>64.3064</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.5313</td>\n",
       "      <td>0</td>\n",
       "      <td>55.2404</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Missing values [%]  Sample standard deviation [Unit of feature]  \\\n",
       "IC6                  0.0                                      14.5106   \n",
       "IC7                  0.0                                       7.9594   \n",
       "IC8                  0.0                                       6.2784   \n",
       "IC9                  0.0                                       7.4381   \n",
       "IC10                 0.0                                       9.6860   \n",
       "IC11                 0.0                                       5.8353   \n",
       "IC12                 0.0                                       3.3463   \n",
       "IC13                 0.0                                       1.9231   \n",
       "IC14                 0.0                                       4.6407   \n",
       "IC15                 0.0                                      12.3411   \n",
       "IC16                 0.0                                       9.1708   \n",
       "IC17                 0.0                                       7.6406   \n",
       "IC18                 0.0                                       8.4727   \n",
       "IC19                 0.0                                      10.6442   \n",
       "IC20                 0.0                                       6.6662   \n",
       "IC21                 0.0                                       3.9072   \n",
       "IC22                 0.0                                       2.3217   \n",
       "IC23                 0.0                                       5.5313   \n",
       "\n",
       "      Minimum [Unit of f.]  Share of Minimum [%]:  Maximum [Unit of f.]  \\\n",
       "IC6                      0                 2.2817                    99   \n",
       "IC7                      0                 1.9473                    99   \n",
       "IC8                      0                 1.6581                    99   \n",
       "IC9                      0                 1.4925                    99   \n",
       "IC10                     0                 2.6464                    99   \n",
       "IC11                     0                15.2622                    99   \n",
       "IC12                     0                40.5546                    50   \n",
       "IC13                     0                64.3776                    61   \n",
       "IC14                     0                54.6787                    99   \n",
       "IC15                     0                 5.8473                    99   \n",
       "IC16                     0                 3.4629                    99   \n",
       "IC17                     0                 2.5615                    99   \n",
       "IC18                     0                 2.0039                    99   \n",
       "IC19                     0                 3.3277                    99   \n",
       "IC20                     0                16.8993                    99   \n",
       "IC21                     0                41.4707                    50   \n",
       "IC22                     0                64.3064                    99   \n",
       "IC23                     0                55.2404                    99   \n",
       "\n",
       "      Share of Maximum [%]  \n",
       "IC6                 0.0283  \n",
       "IC7                 0.0073  \n",
       "IC8                 0.0052  \n",
       "IC9                 0.0157  \n",
       "IC10                0.0084  \n",
       "IC11                0.0010  \n",
       "IC12                0.0021  \n",
       "IC13                0.0021  \n",
       "IC14                0.0021  \n",
       "IC15                0.0367  \n",
       "IC16                0.0136  \n",
       "IC17                0.0115  \n",
       "IC18                0.0210  \n",
       "IC19                0.0115  \n",
       "IC20                0.0021  \n",
       "IC21                0.0021  \n",
       "IC22                0.0021  \n",
       "IC23                0.0031  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nans_variance_min_max(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(households, savefig, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(families, savefig, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**For the same reasoning as above, remove zeros from IC6, ..., IC10 and IC15, ... IC19. For the other ones there are probably a lot of \"false zeros\" as well, but the risk of deleting too many legitimate zeros is too high in my opinion.**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros with nans\n",
    "for feature in [\n",
    "    'IC6', # (\"Percent Households w/ Income < $15,000\")\n",
    "    'IC7', # (\"Percent Households w/ Income $15,000 - $24,999\")\n",
    "    'IC8', # (\"Percent Households w/ Income $25,000 - $34,999\")\n",
    "    'IC9', # (\"Percent Households w/ Income $35,000 - $49,999\")\n",
    "    'IC10', # (\"Percent Households w/ Income $50,000 - $74,999\")\n",
    "    \n",
    "    'IC15', # (\"Percent Families w/ Income < $15,000\")\n",
    "    'IC16', # (\"Percent Families w/ Income $15,000 - $24,999\")\n",
    "    'IC17', # (\"Percent Families w/ Income $25,000 - 34,999\")\n",
    "    'IC18', # (\"Percent Families w/ Income $35,000 - $49,999\")\n",
    "    'IC19', # (\"Percent Families w/ Income $50,000 - $74,999\")\n",
    "]: \n",
    "    remove_value(feature, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**After removing zeros:**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(households, savefig, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(families, savefig, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove value 0 from columns 'HHAS1', 'HHAS2', 'HHAS3', 'HHAS4' ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'HHAS1', # (\"Percent Households on Social Security\")\n",
    "    'HHAS2', # (\"Percent Households on Public Assistance\")\n",
    "    'HHAS3', # (\"Percent Households w/ Interest, Rental or Dividend Income\")\n",
    "    'HHAS4' # (\"Percent Persons Below Poverty Level\")\n",
    "]\n",
    "\n",
    "savefig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing values [%]</th>\n",
       "      <th>Sample standard deviation [Unit of feature]</th>\n",
       "      <th>Minimum [Unit of f.]</th>\n",
       "      <th>Share of Minimum [%]:</th>\n",
       "      <th>Maximum [Unit of f.]</th>\n",
       "      <th>Share of Maximum [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HHAS1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.8649</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2357</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHAS2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2156</td>\n",
       "      <td>0</td>\n",
       "      <td>10.6423</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHAS3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0543</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0911</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HHAS4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.9674</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5665</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Missing values [%]  Sample standard deviation [Unit of feature]  \\\n",
       "HHAS1                 0.0                                      13.8649   \n",
       "HHAS2                 0.0                                       6.2156   \n",
       "HHAS3                 0.0                                      17.0543   \n",
       "HHAS4                 0.0                                       9.9674   \n",
       "\n",
       "       Minimum [Unit of f.]  Share of Minimum [%]:  Maximum [Unit of f.]  \\\n",
       "HHAS1                     0                 1.2357                    99   \n",
       "HHAS2                     0                10.6423                    99   \n",
       "HHAS3                     0                 1.0911                    99   \n",
       "HHAS4                     0                 4.5665                    99   \n",
       "\n",
       "       Share of Maximum [%]  \n",
       "HHAS1                0.0189  \n",
       "HHAS2                0.0052  \n",
       "HHAS3                0.0314  \n",
       "HHAS4                0.0073  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nans_variance_min_max(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**For the same reasons as above, delete zeros from HHAS1, HHAS2 and HHAS3, but not HHAS4.**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros with nans\n",
    "for feature in ['HHAS1','HHAS2','HHAS3',]: \n",
    "    remove_value(feature, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**After removing zeros:**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove value 0 and 99 from columns 'LFC1', 'LFC2', 'LFC3', 'LFC4', 'LFC5', 'LFC6', 'LFC7', 'LFC8', 'LFC9', 'LFC10' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'LFC1', # (\"Percent Adults in Labor Force\")\n",
    "    'LFC2', # (\"Percent Adult Males in Labor Force\")\n",
    "    'LFC3', # (\"Percent Females in Labor Force\")\n",
    "    'LFC4', # (\"Percent Adult Males Employed\")\n",
    "    'LFC5', # (\"Percent Adult Females Employed\")\n",
    "    'LFC6', # (\"Percent Mothers Employed Married and Single\")\n",
    "    'LFC7', # (\"Percent 2 Parent Earner Families\")\n",
    "    'LFC8', # (\"Percent Single Mother w/ Child in Labor Force\")\n",
    "    'LFC9', # (\"Percent Single Father w/ Child in Labor Force\")\n",
    "    'LFC10' # (\"Percent Families w/ Child w/ no Workers\")\n",
    "]\n",
    "\n",
    "savefig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing values [%]</th>\n",
       "      <th>Sample standard deviation [Unit of feature]</th>\n",
       "      <th>Minimum [Unit of f.]</th>\n",
       "      <th>Share of Minimum [%]:</th>\n",
       "      <th>Maximum [Unit of f.]</th>\n",
       "      <th>Share of Maximum [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LFC1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.6016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LFC2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.6434</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>99</td>\n",
       "      <td>0.2473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LFC3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.7419</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9611</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LFC4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.9831</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9611</td>\n",
       "      <td>99</td>\n",
       "      <td>0.1457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LFC5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.7423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LFC6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3900</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0301</td>\n",
       "      <td>99</td>\n",
       "      <td>1.5858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LFC7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.2824</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6464</td>\n",
       "      <td>99</td>\n",
       "      <td>0.4255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LFC8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>30.7682</td>\n",
       "      <td>0</td>\n",
       "      <td>9.7608</td>\n",
       "      <td>99</td>\n",
       "      <td>29.6147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LFC9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>44.7209</td>\n",
       "      <td>0</td>\n",
       "      <td>31.9666</td>\n",
       "      <td>99</td>\n",
       "      <td>49.1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LFC10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.2495</td>\n",
       "      <td>0</td>\n",
       "      <td>29.4743</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Missing values [%]  Sample standard deviation [Unit of feature]  \\\n",
       "LFC1                  0.0                                      13.6016   \n",
       "LFC2                  0.0                                      14.6434   \n",
       "LFC3                  0.0                                      13.7419   \n",
       "LFC4                  0.0                                      14.9831   \n",
       "LFC5                  0.0                                      13.7423   \n",
       "LFC6                  0.0                                      16.3900   \n",
       "LFC7                  0.0                                      17.2824   \n",
       "LFC8                  0.0                                      30.7682   \n",
       "LFC9                  0.0                                      44.7209   \n",
       "LFC10                 0.0                                       9.2495   \n",
       "\n",
       "       Minimum [Unit of f.]  Share of Minimum [%]:  Maximum [Unit of f.]  \\\n",
       "LFC1                      0                 0.9213                    99   \n",
       "LFC2                      0                 0.9506                    99   \n",
       "LFC3                      0                 0.9611                    99   \n",
       "LFC4                      0                 0.9611                    99   \n",
       "LFC5                      0                 0.9716                    99   \n",
       "LFC6                      0                 2.0301                    99   \n",
       "LFC7                      0                 2.6464                    99   \n",
       "LFC8                      0                 9.7608                    99   \n",
       "LFC9                      0                31.9666                    99   \n",
       "LFC10                     0                29.4743                    99   \n",
       "\n",
       "       Share of Maximum [%]  \n",
       "LFC1                 0.0367  \n",
       "LFC2                 0.2473  \n",
       "LFC3                 0.0451  \n",
       "LFC4                 0.1457  \n",
       "LFC5                 0.0388  \n",
       "LFC6                 1.5858  \n",
       "LFC7                 0.4255  \n",
       "LFC8                29.6147  \n",
       "LFC9                49.1993  \n",
       "LFC10                0.0943  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nans_variance_min_max(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**These 0 and 99 values are weird. Delete them.**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros with nans\n",
    "for feature in features: \n",
    "    remove_value(feature, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 99s with nans\n",
    "for feature in features: \n",
    "    remove_value(feature, 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Check:**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Also remove 50s from LFC9**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 50s with nans for LFC9\n",
    "remove_value('LFC9', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**After removing values:**<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch:\n",
    "    many_hists(features, savefig, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove value 0 for ACF4 and ACF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros with nans for ACF4 and ACF5\n",
    "remove_value('AFC4', 0)\n",
    "remove_value('AFC5', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat the cases where 'LASTDATE' suggests that donor is not lapsing or lapsed (In this dataset, all donors should be either lapsing or lapsed)\n",
    "\n",
    "<span style=\"color:red\">**We have to check this! I feel like I remove too many observations here.**<span>\n",
    "\n",
    "Forum entry \"Lapsed donors\"\n",
    "\n",
    "Entry by David Silva - Thursday, 3 December 2020, 9:43 AM\n",
    " \t\n",
    "\"Hi Philipp,\n",
    "\n",
    "Yes. A lapsed donor is a \"snapshot\" label so it depends on a point in time. The lapsed donors in this dataset are determined according to the date the last promotion (17NK) was emailed to each one of them and the date of their most recent gift. Inconsistent observations are the ones which have an interval between these two dates smaller than 13 months as according to the Lapsed donors description: \"A previous donor who made their donation between 13-24 months ago\".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only execute if flag=True\n",
    "flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag:\n",
    "    # Create a series that contains the dates from 'adate_2' substacted by 13 months\n",
    "    adate_2_minus_13_months = donors.ADATE_2.map(lambda x: x - dateutil.relativedelta.relativedelta(months=13))\n",
    "    adate_2_minus_13_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag:\n",
    "    # Check if it worked properly\n",
    "    (donors.ADATE_2 - adate_2_minus_13_months) / 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag:\n",
    "    # Remove inconsistent values from donors\n",
    "    # Inconsistent values are the ones where 'adate_2_minus_13_months' is before 'LASTDATE'\n",
    "    # All observations that are not inconsistent are kept.\n",
    "    donors_2 = donors[~(adate_2_minus_13_months < donors['LASTDATE'])]\n",
    "\n",
    "    percentage_discarded = ((donors.shape[0] - donors_2.shape[0]) / donors.shape[0])*100\n",
    "    print('Percentage of observation discarded due to inconsistency between their \"lapsed\" status and their LASTDATE value:')\n",
    "    print(round(percentage_discarded, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag:\n",
    "    # Accept the changes\n",
    "    donors = donors_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discard features that add little additional information\n",
    "**Approach: Identify which variables are highly correlated to each other (pandas-profiling is of great help here) and of these groups plot the covariances and their single and common distributions as well as compute their missing value percentages and their sample standard errors. With this information decide which ones to discard and which ones to keep.**\n",
    "\n",
    "**Workflow: Paste features that are to be looked at into 'features' in the following cell. Then execute all cells of this step. Make decisions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'HC17', # (\"Percent Housing Units w/ Public Water Source\")\n",
    "    'HC18' # (\"Percent Housing Units w/ Well Water Source\")\n",
    "]\n",
    "\n",
    "savefig = False\n",
    "switch_2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    uniques_nans_variance(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing values [%]</th>\n",
       "      <th>Sample standard deviation [Unit of feature]</th>\n",
       "      <th>Minimum [Unit of f.]</th>\n",
       "      <th>Share of Minimum [%]:</th>\n",
       "      <th>Maximum [Unit of f.]</th>\n",
       "      <th>Share of Maximum [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HC17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.4653</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7240</td>\n",
       "      <td>99</td>\n",
       "      <td>52.3184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>26.7041</td>\n",
       "      <td>0</td>\n",
       "      <td>48.8513</td>\n",
       "      <td>99</td>\n",
       "      <td>1.6434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Missing values [%]  Sample standard deviation [Unit of feature]  \\\n",
       "HC17                 0.0                                      28.4653   \n",
       "HC18                 0.0                                      26.7041   \n",
       "\n",
       "      Minimum [Unit of f.]  Share of Minimum [%]:  Maximum [Unit of f.]  \\\n",
       "HC17                     0                 2.7240                    99   \n",
       "HC18                     0                48.8513                    99   \n",
       "\n",
       "      Share of Maximum [%]  \n",
       "HC17               52.3184  \n",
       "HC18                1.6434  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nans_variance_min_max(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HC17    28.4653\n",
       "HC18    26.7041\n",
       "Name: Sample standard deviation [Unit of feature], dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nans_variance_min_max(features)['Sample standard deviation [Unit of feature]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_2:\n",
    "    corr_matrix_visualisation(features, savefig, 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch_2:\n",
    "    corr_matrix_visualisation(features, savefig, 'spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch_2:\n",
    "    many_hists(features, savefig, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch_2:\n",
    "    many_boxplots(features, savefig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if switch_2:\n",
    "    t_before = datetime.datetime.now()\n",
    "\n",
    "    create_kdeplot = False\n",
    "\n",
    "    pairwise(features, create_kdeplot)\n",
    "\n",
    "    t_after = datetime.datetime.now()\n",
    "    print('Computation time = ', t_after - t_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features to drop: 92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RECP3',\n",
       " 'RP2',\n",
       " 'HVP6',\n",
       " 'MAILCODE',\n",
       " 'AGE905',\n",
       " 'IC17',\n",
       " 'OCC9',\n",
       " 'IC13',\n",
       " 'AGEC6',\n",
       " 'LFC5',\n",
       " 'HHAGE2',\n",
       " 'LFC4',\n",
       " 'RFA_2R',\n",
       " 'AGE907',\n",
       " 'CONTROLN',\n",
       " 'LFC1',\n",
       " 'HHN6',\n",
       " 'IC12',\n",
       " 'HC7',\n",
       " 'POP902',\n",
       " 'IC9',\n",
       " 'IC10',\n",
       " 'HVP4',\n",
       " 'RHP2',\n",
       " 'DW1',\n",
       " 'IC15',\n",
       " 'NOEXCH',\n",
       " 'TCODE',\n",
       " 'POP90C4',\n",
       " 'IC5',\n",
       " 'ETH11',\n",
       " 'IC22',\n",
       " 'MARR1',\n",
       " 'HHD9',\n",
       " 'HHP2',\n",
       " 'DW8',\n",
       " 'ETHC5',\n",
       " 'HU2',\n",
       " 'IC20',\n",
       " 'HV2',\n",
       " 'IC18',\n",
       " 'HHD5',\n",
       " 'ETH13',\n",
       " 'RECPGVG',\n",
       " 'CARDGIFT',\n",
       " 'IC4',\n",
       " 'AFC1',\n",
       " 'RHP3',\n",
       " 'IC1',\n",
       " 'IC23',\n",
       " 'RHP1',\n",
       " 'AFC4',\n",
       " 'HUPA2',\n",
       " 'IC11',\n",
       " 'DW6',\n",
       " 'HC18',\n",
       " 'HHAGE3',\n",
       " 'IC16',\n",
       " 'ETH15',\n",
       " 'LFC2',\n",
       " 'IC8',\n",
       " 'LSC2',\n",
       " 'HHAGE1',\n",
       " 'CARDPROM',\n",
       " 'IC3',\n",
       " 'HHN1',\n",
       " 'IC14',\n",
       " 'RP4',\n",
       " 'MARR3',\n",
       " 'LFC3',\n",
       " 'TPE4',\n",
       " 'MAJOR',\n",
       " 'POP903',\n",
       " 'HHN4',\n",
       " 'HV3',\n",
       " 'HHN3',\n",
       " 'DW5',\n",
       " 'RP1',\n",
       " 'HV4',\n",
       " 'AGE903',\n",
       " 'IC21',\n",
       " 'HVP1',\n",
       " 'ETH12',\n",
       " 'ETHC4',\n",
       " 'RECSWEEP',\n",
       " 'HVP2',\n",
       " 'AGE904',\n",
       " 'AGE906',\n",
       " 'RECINHSE',\n",
       " 'HUPA6',\n",
       " 'AGE902',\n",
       " 'IC7']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Following direction of pandas profiling (html file in folder \"pandas-profiling/2020-12-15 14/50/43.266760\"),\n",
    "# determine which features to drop right away:\n",
    "to_drop = [\n",
    "    \n",
    "    # 'RFA_2R' # (\"Recency code for RFA_2\") \n",
    "    \n",
    "    # Is a column with a constant value. No variance, no information. Drop it.\n",
    "    \n",
    "    'RFA_2R',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'POP901', # (\"Number of Persons\")\n",
    "    # 'POP902', # (\"Number of Families\")\n",
    "    # 'POP903' # (\"Number of Households\")\n",
    "    \n",
    "    # 'POP902' and 'POP903' are both highly correlated with 'POP901'.\n",
    "    \n",
    "    # None of the three have missing values.\n",
    "    \n",
    "    # Keep 'POP901'. Drop the other two.\n",
    "    \n",
    "    'POP902', \n",
    "    'POP903',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'ETH13', # (\"Percent Mexican\") \n",
    "    # 'ETH5', # (\"Percent Hispanic\")\n",
    "    # 'LSC2' # (\"Percent Spanish Speaking\")\n",
    "    \n",
    "    # None have missing values.\n",
    "    \n",
    "    # Sample standard deviations:\n",
    "    # ETH13    11.3335\n",
    "    # ETH5     13.7861\n",
    "    # LSC2     12.0437\n",
    "    \n",
    "    # -> Keep 'ETH5'\n",
    "    \n",
    "    'ETH13',\n",
    "    'LSC2',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'AGE901', # (\"Median Age of Population\")\n",
    "    # 'AGE902', # (\"Median Age of Adults 18 or Older\")\n",
    "    # 'AGE903', # (\"Median Age of Adults 25 or Older\"\n",
    "    # 'AGE904', # (\"Average Age of Population\"). Carries slightly less information (in the variance sense) than 'AGE901': Sample standard deviations: 7.2612 years vs. 8.3356 years\n",
    "    # 'AGE905', # (\"Average Age of Adults >= 18\")\n",
    "    # 'AGE906' # (\"Average Age of Adults >= 25\")\n",
    "    \n",
    "    # The latter 5 are highly correlated with 'AGE901'.\n",
    "    \n",
    "    # All have the same amount of missing values.\n",
    "    \n",
    "    # Sample standard deviations:\n",
    "    # AGE901    7.7426\n",
    "    # AGE902    7.3261\n",
    "    # AGE903    6.9989\n",
    "    # AGE904    6.4949\n",
    "    # AGE905    5.6426\n",
    "    # AGE906    5.3142\n",
    "    \n",
    "    # -> Keep only 'AGE901'\n",
    "    \n",
    "    'AGE902', \n",
    "    'AGE903', \n",
    "    'AGE904', \n",
    "    'AGE905',\n",
    "    'AGE906',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'HHAGE1', # (\"Percent Households w/ Person 65+\"\").\n",
    "    # 'AGEC6', # (\"Percent Adults Age 65-74\")\n",
    "    # 'HHAGE2', # (\"Percent Households w/ Person 65+ Living Alone\")\n",
    "    # 'HHAGE3', # (\"Percent Households Headed by an Elderly Person Age 65+\")\n",
    "    \n",
    "    # 'AGEC6', 'HHAGE2', 'HHAGE3' are highly correlated with 'HHAGE1'.\n",
    "    \n",
    "    # These four features have a similar meaning.\n",
    "    \n",
    "    # None have missing values.\n",
    "    \n",
    "    # Sample standard deviations:\n",
    "    # HHAGE1    13.0903\n",
    "    # AGEC6      6.0038\n",
    "    # HHAGE2     7.4415\n",
    "    # HHAGE3    12.9639\n",
    "    \n",
    "    # -> 'HHAGE1' has the highest variance. Keep it. Drop the rest.\n",
    "    \n",
    "    'AGEC6',\n",
    "    'HHAGE2',\n",
    "    'HHAGE3',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'HHN1', # (\"Percent 1 Person Households\")\n",
    "    # 'HHN2', # (\"Percent 2 Person Households\")\n",
    "    # 'HHN3', # (\"Percent 3 or More Person Households\")\n",
    "    # 'HHN4', # (\"Percent 4 or More Person Households\")\n",
    "    # 'HHN5', # (\"Percent 5 or More Person Households\")\n",
    "    # 'HHN6' # (\"Percent 6 Person Households\")\n",
    "    # 3, 4 and 5, 6 are highly correlated with each other and have similar meanings.\n",
    "    # Sample standard deviations:\n",
    "    # HHN3: 14.5385 %\n",
    "    # HHN4: 11.0592 %\n",
    "    # -> Keep HHN3\n",
    "    # HHN5: 6.3828 %\n",
    "    # HHN6: 3.793 %\n",
    "    # -> Keep HHN5\n",
    "    # -> Drop HHN4, HHN6:\n",
    "    \n",
    "    'HHN4',\n",
    "    'HHN6',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'MARR3', # (\"Percent Widowed\")\n",
    "    # 'AGEC7' # (\"Percent Adults Age >= 75\")\n",
    "    \n",
    "    # When there are many old people, there are also many widowed people.\n",
    "    \n",
    "    # Both have no nan values.\n",
    "    \n",
    "    # -> Drop the one with smaller variance.\n",
    "    \n",
    "    # Sample standard deviation:\n",
    "    # MARR3: 4.8877 %\n",
    "    # AGEC7: 6.7237 %\n",
    "    \n",
    "    'MARR3',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'HHP1', # (\"Median Person Per Household\")\n",
    "    # 'HHP2', # (\"Average Person Per Household\")\n",
    "    # 'HHN3', # (\"Percent 3 or More Person Households\")\n",
    "    # 'HHN4', # (\"Percent 4 or More Person Households\")\n",
    "    # 'HHD1', # (\"Percent Households w/ Related Children\")\n",
    "    # 'RHP3' # (\"Median Number of Persons per Housing Unit\")\n",
    "    \n",
    "    # Sample standard deviations:\n",
    "    # HHP1    50.0412 people\n",
    "    # HHP2    49.9018 people\n",
    "    # HHN3    14.5385 %\n",
    "    # HHN4    11.0592 %\n",
    "    # HHD1    13.0351 %\n",
    "    # RHP3     2.5598 people\n",
    "    \n",
    "    # My personal opinion: 'HHP1' has a different meaning to the other 5. Let's keep it.\n",
    "    \n",
    "    # But the other 5 are pretty similar to each other.\n",
    "    \n",
    "    # None of them have missing values.\n",
    "    \n",
    "    # 'RHP3' and 'HHP2' have a lower variance than 'HHP1'. Let's drop them.\n",
    "    # 'HHN4' has a lower variance than 'HHN3'. Let's drop it.\n",
    "    \n",
    "    # Out of 'HHP1' and 'HHN3', 'HHP1' is less correlated with 'HHD1' (which we decided to keep). \n",
    "    # This holds for both Pearson and Spearman correlation. So let's drop 'HHN3'\n",
    "    \n",
    "    'HHP2',\n",
    "    'HHN4',\n",
    "    'RHP3',\n",
    "    'HHN3',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'DW1',   # Percent Single Unit Structure\n",
    "    # 'DW2',   # Percent Detached Single Unit Structure\n",
    "    # 'DW3',   # Percent Duplex Structure\n",
    "    # 'DW4',   # Percent Multi (2+) Unit Structures\n",
    "    # 'DW5',   # Percent 3+ Unit Structures\n",
    "    # 'DW6',   # Percent Housing Units in 5+ Unit Structure\n",
    "    # 'DW7',   # Percent Group Quarters\n",
    "    # 'DW8',   # Percent Institutional Group Quarters\n",
    "    # 'DW9',   # Non-Institutional Group Quarters\n",
    "    # 'HUPA2', # Percent Housing Units w/ >= 10 Units at the Address\n",
    "    # 'HUPA6'  # Percent Renter Occupied, 5+ Units\n",
    "    \n",
    "    # Sample standard deviations:\n",
    "    # DW1      24.9746 % (Drop this one and...)\n",
    "    # DW2      26.3531 % (...keep this one)\n",
    "    # DW3       5.3653 % (Pretty independant from the rest. Keep it.)\n",
    "    # DW4      23.8544 % (This one is highly correlated with DW4, DW5, DW6 and HUPA2, HUPA6. Keep DW4 and drop them.)\n",
    "    # DW5      22.6455 % (Drop)\n",
    "    # DW6      20.4578 % (Drop)\n",
    "    # DW7       5.9069 % (Highly correlated with DW8. Keep this one and drop DW8)\n",
    "    # DW8       4.2548 % (Drop)\n",
    "    # DW9       3.9695 % (I assume it's % as well) (Pretty independant from the rest. Keep it.)\n",
    "    # HUPA2    17.1094 % (Drop)\n",
    "    # HUPA6    17.8080 % (Drop)\n",
    "    \n",
    "    'DW1',\n",
    "    'DW5',\n",
    "    'DW6',\n",
    "    'DW8',\n",
    "    'HUPA2',\n",
    "    'HUPA6',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'RP1', # (\"Percent Renters Paying >= $500 per Month\")\n",
    "    # 'RP2', # (\"Percent Renters Paying >= $400 per Month\")\n",
    "    # 'RP3', # (\"Percent Renters Paying >= $300 per Month\")\n",
    "    # 'RP4', # (\"Percent Renters Paying >= $200 per Month\")\n",
    "    # 'HV4' # (\"Average Contract Rent in hundreds\")\n",
    "    \n",
    "    # These are all highly correlated.\n",
    "    \n",
    "    # Keeping only RP3 since it is amongs the ones with the highest variance (Note that HV4 can not be included in the\n",
    "    # comparison because it is on a totally different scale) and since after the removal of zeros in the previous step\n",
    "    # its distribution seems to be the most well behaved. Dropping the other ones.\n",
    "    \n",
    "    'RP1',\n",
    "    'RP2',\n",
    "    'RP4',\n",
    "    'HV4',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'IC1', # (\"Median Household Income in hundreds\")\n",
    "    # 'IC2', # (\"Median Family Income in hundreds\")\n",
    "    # 'IC3', # (\"Average Household Income in hundreds\")\n",
    "    # 'IC4', # (\"Average Family Income in hundreds\")\n",
    "    # 'IC5' # (\"Per Capita Income\")\n",
    "    \n",
    "    # IC2 has the highest variance out of the first four (Note that IC5 can not be included in the comparison because \n",
    "    # it is on a totally different scale) and it looks like the most well behaved distribution. Keep IC2 and drop the\n",
    "    # other ones.\n",
    "    \n",
    "    'IC1',\n",
    "    'IC3',\n",
    "    'IC4',\n",
    "    'IC5',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'IC6', # (\"Percent Households w/ Income < $15,000\")\n",
    "    # 'IC7', # (\"Percent Households w/ Income $15,000 - $24,999\")\n",
    "    # 'IC8', # (\"Percent Households w/ Income $25,000 - $34,999\")\n",
    "    # 'IC9', # (\"Percent Households w/ Income $35,000 - $49,999\")\n",
    "    # 'IC10', # (\"Percent Households w/ Income $50,000 - $74,999\")\n",
    "    # 'IC11', # (\"Percent Households w/ Income $75,000 - $99,999\")\n",
    "    # 'IC12', # (\"Percent Households w/ Income $100,000 - $124,999\")\n",
    "    # 'IC13', # (\"Percent Households w/ Income $125,000 - $149,999\")\n",
    "    # 'IC14', # (\"Percent Households w/ Income >= $150,000\")\n",
    "    # 'IC15', # (\"Percent Families w/ Income < $15,000\")\n",
    "    # 'IC16', # (\"Percent Families w/ Income $15,000 - $24,999\")\n",
    "    # 'IC17', # (\"Percent Families w/ Income $25,000 - 34,999\")\n",
    "    # 'IC18', # (\"Percent Families w/ Income $35,000 - $49,999\")\n",
    "    # 'IC19', # (\"Percent Families w/ Income $50,000 - $74,999\")\n",
    "    # 'IC20', # (\"Percent Families w/ Income $75,000 - $99,999\")\n",
    "    # 'IC21', # (\"Percent Families w/ Income $100,000 - $124,999\")\n",
    "    # 'IC22', # (\"Percent Families w/ Income $125,000 - $149,999\")\n",
    "    # 'IC23' # (\"Percent Families w/ Income >= $150,000\")\n",
    "    \n",
    "    # Naturally, IC6 is highly correlated with IC15 and so on. So having both sets of features would be quite \n",
    "    # redundant. \n",
    "    \n",
    "    # Looking at the variance (see sample standard deviations table below), it could be said that IC6 / IC 15 and\n",
    "    # IC10 / IC 19 give the most information. The first is an indicator for the amount of poor households, the latter\n",
    "    # an indicator for the amount of \"medium\" households. Idea: Keep one of each: The one with the higher variance, so\n",
    "    # keep IC6 and IC19 and drop the rest. IC6 and IC19 have rather well behaved distributions as well.\n",
    "    \n",
    "    # Sample standard deviations: \n",
    "    # IC   \"Household\"   IC  \"Families\"\n",
    "    # 6    14.2979     15    12.1377\n",
    "    # 7    7.6694      16    8.8146\n",
    "    # 8    5.9860      17    7.2545\n",
    "    # 9    7.1408      18    8.0242\n",
    "    # 10   9.4480      19    10.2369\n",
    "    # 11   5.8353      20    6.6662\n",
    "    # 12   3.3463      21    3.9072\n",
    "    # 13   1.9231      22    2.3217\n",
    "    # 14   4.6407      23    5.5313\n",
    "    \n",
    "    'IC7',\n",
    "    'IC8',\n",
    "    'IC9',\n",
    "    'IC10',\n",
    "    'IC11',\n",
    "    'IC12',\n",
    "    'IC13',\n",
    "    'IC14',\n",
    "    'IC15',\n",
    "    'IC16',\n",
    "    'IC17',\n",
    "    'IC18',\n",
    "    'IC20',\n",
    "    'IC21',\n",
    "    'IC22',\n",
    "    'IC23',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'HHAGE1' # (\"Percent Households w/ Person 65+\") (Decided to keep this one, see above in this cell.)\n",
    "    # 'HHAS1' # (\"Percent Households on Social Security\")\n",
    "    # 'HHAS2' # (\"Percent Households on Public Assistance\")\n",
    "    # 'HHAS3' # (\"Percent Households w/ Interest, Rental or Dividend Income\")\n",
    "    # 'HHAS4' # (\"Percent Persons Below Poverty Level\")\n",
    "    \n",
    "    # HHAGE1 and HHAS1 are highly correlated. HHAS1 looks more well behaved. Keep HHAS1 Drop HHAGE1.\n",
    "    \n",
    "    'HHAGE1', # (\"Percent Households w/ Person 65+\")\"\n",
    "    \n",
    "    # Confirming this decision by double checking with this combination of features:\n",
    "    \n",
    "    # 'HHAS1' # (\"Percent Households on Social Security\") \n",
    "    # 'AGEC6', # (\"Percent Adults Age 65-74\")\n",
    "    # 'HHAGE1', # (\"Percent Households w/ Person 65+\"\").\n",
    "    # 'HHAGE2', # (\"Percent Households w/ Person 65+ Living Alone\")\n",
    "    # 'HHAGE3', # (\"Percent Households Headed by an Elderly Person Age 65+\")\n",
    "    \n",
    "    # These are all highly correlated.\n",
    "    \n",
    "    # Sample standard deviations:\n",
    "    # HHAS1     13.6223\n",
    "    # AGEC6      5.9319\n",
    "    # HHAGE1    12.9246\n",
    "    # HHAGE2     7.4415\n",
    "    # HHAGE3    12.8220\n",
    "    \n",
    "    # A look at the combination above confirms the decision to keep HHAS1 since it has the highest variance out of\n",
    "    # these ones.\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'TPE1', # (\"Percent Driving to Work Alone Car/Truck/Van\")\n",
    "    # 'TPE2', # (\"Percent Carpooling Car/Truck/Van)\")\n",
    "    # 'TPE3', # (\"Percent Using Public Transportation\")\n",
    "    # 'TPE4', # (\"Percent Using Bus/Trolley\")\n",
    "    # 'TPE5', # (\"Percent Using Railways\")\n",
    "    # 'TPE6', # (\"Percent Using Taxi/Ferry\")\n",
    "    # 'TPE7', # (\"Percent Using Motorcycles\")\n",
    "    # 'TPE8', # (\"Percent Using Other Transportation\")\n",
    "    # 'TPE9' # (\"Percent Working at Home/No Transportation\")\n",
    "    \n",
    "    # Could think about dropping either TPE3 or TPE4 since they are correlated.\n",
    "    \n",
    "    # Drop 'TPE4'\n",
    "    \n",
    "    'TPE4',\n",
    "    \n",
    "    # Also note: If used, it would be good to delete the zeros at least from TPE1 and TPE2\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'LFC1', # (\"Percent Adults in Labor Force\")\n",
    "    # 'LFC2', # (\"Percent Adult Males in Labor Force\")\n",
    "    # 'LFC3', # (\"Percent Females in Labor Force\")\n",
    "    # 'LFC4', # (\"Percent Adult Males Employed\")\n",
    "    # 'LFC5', # (\"Percent Adult Females Employed\")\n",
    "    # 'LFC6', # (\"Percent Mothers Employed Married and Single\")\n",
    "    # 'LFC7', # (\"Percent 2 Parent Earner Families\")\n",
    "    # 'LFC8', # (\"Percent Single Mother w/ Child in Labor Force\")\n",
    "    # 'LFC9', # (\"Percent Single Father w/ Child in Labor Force\")\n",
    "    # 'LFC10' # (\"Percent Families w/ Child w/ no Workers\")\n",
    "    \n",
    "    # LFC1,2,3,4,5 are highly correlated. Keep LFC4 (highest variance). Drop the rest.\n",
    "    \n",
    "    'LFC1',\n",
    "    'LFC2',\n",
    "    'LFC3',\n",
    "    'LFC4',\n",
    "    'LFC5',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "\n",
    "    # 'EIC1', # (\"Percent Employed in Agriculture\")\n",
    "    # 'OCC9' # (\"Percent Farmers\")\n",
    "    \n",
    "    # Sample standard deviations:\n",
    "    # EIC1    5.5708\n",
    "    # OCC9    5.1068\n",
    "    \n",
    "    # -> Keep EIC1, drop OCC9\n",
    "    \n",
    "    'OCC9',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'AFC1', # (\"Percent Adults in Active Military Service\")\n",
    "    # 'AFC2', # (\"Percent Males in Active Military Service\")\n",
    "    # 'AFC3', # (\"Percent Females in Active Military Service\")\n",
    "    # 'AFC4', # (\"Percent Adult Veterans Age 16+\")\n",
    "    # 'AFC5', # (\"Percent Male Veterans Age 16+\")\n",
    "    # 'AFC6' # (\"Percent Female Veterans Age 16+\")\n",
    "    \n",
    "    # Sample standard deviations:\n",
    "    # AFC1     3.1694\n",
    "    # AFC2     4.9033\n",
    "    # AFC3     1.0661\n",
    "    # AFC4     5.2705\n",
    "    # AFC5    10.4757\n",
    "    # AFC6     1.6404\n",
    "    \n",
    "    # ACF4 and ACF5 are highly correlated. Drop AFC4 (lower variance).\n",
    "    # Same for ACF1 and ACF2. Drop ACF1.\n",
    "    \n",
    "    'AFC1', # (\"Percent Adults in Active Military Service\")\n",
    "    'AFC4', # (\"Percent Adult Veterans Age 16+\")\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'HC1',\n",
    "    # 'HC2',\n",
    "    # 'HC3',\n",
    "    # 'HC4',\n",
    "    # 'HC5',\n",
    "    # 'HC6',\n",
    "    # 'HC7', # (\"Percent Owner Occupied Structures Built Since 1980\")\n",
    "    # 'HC8' # (\"Percent Owner Occupied Structures Built Prior to 1860\")\n",
    "    \n",
    "    # HC7, HC8 are highly negatively correlated.\n",
    "    \n",
    "    'HC7',\n",
    "    \n",
    "    # Consider dropping HC3, ..., HC8. Not sure about HC1 and HC2.\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'HC17', # (\"Percent Housing Units w/ Public Water Source\")\n",
    "    # 'HC18' # (\"Percent Housing Units w/ Well Water Source\")\n",
    "    \n",
    "    # Highly negatively correlated. Dopping one.\n",
    "    \n",
    "    'HC18',\n",
    "\n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'CARDPROM', # (\"Lifetime number of card promotions received to date.\")\n",
    "    # 'NUMPROM', # (\"Lifetime number of promotions received to date\")\n",
    "    \n",
    "    # Highly correlated. Drop one.\n",
    "    \n",
    "    'CARDPROM',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'CARDGIFT', # (\"Number of lifetime gifts to card promotions to date\")\n",
    "    # 'NGIFTALL', # (\"Number of lifetime gifts to date\")\n",
    "    \n",
    "    # Highly correlated. Drop one.\n",
    "    \n",
    "    'CARDGIFT',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "    \n",
    "    # 'CONTROLN', # (\"Control number, unique record identifier\") \n",
    "    # 100% distinct values. Drop it.\n",
    "\n",
    "    'CONTROLN',\n",
    "\n",
    "    #====================\n",
    "    #====================\n",
    "\n",
    "    # 'TCODE', # (\"Donors title code\") \n",
    "    # Doesn’t represent relevant information for clustering and >40% are zeros. Drop it.\n",
    "\n",
    "    'TCODE',\n",
    "\n",
    "    #====================\n",
    "    #====================\n",
    "\n",
    "    # ‘MAILCODE’, # (“Mail Code”)\n",
    "    # Doesn’t represent relevant information for clustering. Drop it\n",
    "\n",
    "    'MAILCODE',\n",
    "\n",
    "    #====================\n",
    "    #====================\n",
    "\n",
    "    # ‘NOEXCH’, # (“Do not exchange flag”)\n",
    "    # Doesn’t represent relevant information for clustering. Drop it\n",
    "\n",
    "    'NOEXCH',\n",
    "\n",
    "    #====================\n",
    "    #====================\n",
    "\n",
    "    # ‘RECINHSE’\n",
    "    # ‘RECP3’\n",
    "    # ‘RECPGVG’\n",
    "    # ‘RECSWEEP’\n",
    "    # ‘MAJOR’\n",
    "\n",
    "    # All the above feature have really low variance and are binary. Nearly constant. Drop them.\n",
    "\n",
    "    'RECINHSE',\n",
    "    'RECP3',\n",
    "    'RECPGVG',\n",
    "    'RECSWEEP',\n",
    "    'MAJOR',\n",
    "\n",
    "    #====================\n",
    "    #====================\n",
    "\n",
    "    # ‘POP90C4’ (“Percent of Male in the neighbourhood”)\n",
    "    # ‘POP90C5’ (“Percent of Female in the neighbourhood”)\n",
    "\n",
    "    # This 2 must be highly negatively correlated since one implies the opposite on the other. \n",
    "    # Only need to keep 1. Let’s keep ‘POP90C5’ for example.\n",
    "\n",
    "    'POP90C4',\n",
    "\n",
    "    #====================\n",
    "    #====================\n",
    "\n",
    "    # ‘ETH2’\n",
    "    # ‘ETHC4’\n",
    "    # ‘ETHC5’\n",
    "\n",
    "    # Both ‘ETHC4 and ‘ETCH15’ are highly correlated with ‘ETH2’.\n",
    "\n",
    "    # Keep ‘ETH2’ and drop the other 2\n",
    "\n",
    "    'ETHC4',\n",
    "    'ETHC5',\n",
    "\n",
    "    #====================\n",
    "    #====================\n",
    "\n",
    "    # ‘ETH5’\n",
    "    # ‘ETH13’\n",
    "    # ‘LSC2’\n",
    "\n",
    "    # Both ‘ETH13 and ‘LSC2’ are highly correlated with ‘ETH5’.\n",
    "\n",
    "    # Keep ‘ETH5’ and drop the other 2\n",
    "\n",
    "    'ETH13',\n",
    "    'LSC2',\n",
    "\n",
    "    #====================\n",
    "    #====================\n",
    "\n",
    "    # ‘ETH11’\n",
    "    # ‘ETH12’\n",
    "    # ‘ETH15’\n",
    "\n",
    "    # All have zeros in near 90% entries. Approximately constant. Drop them.\n",
    "\n",
    "    'ETH11',\n",
    "    'ETH12',\n",
    "    'ETH15',\n",
    "\n",
    "    #====================\n",
    "    #====================\n",
    "\n",
    "    # ‘HV1’, # (“Median Home Value in hundreds”)\n",
    "    # ‘HV2’, # (“Average Home Value in hundreds”)\n",
    "    # ‘HV3’, # (“Median Contract Rent Value in hundreds”)\n",
    "    # ‘HV4’, # (“Average Contract Rent Value in hundreds”)\n",
    "    # ‘HVP6’, # (“Percent Home Value >= $ 300,000”)\n",
    "    # ‘HVP2’, # (“Percent Home Value >= $ 150,000”)\n",
    "    # ‘RP1’, # (“Percent Renters Paying >= $500 per Month”)\n",
    "\n",
    "    # ‘HV1’, ‘HV2’, - highly correlated \n",
    "    # ‘HV1’, ’HVP6’ - highly correlated\n",
    "    # ‘HV2’, ‘HVP2’ - highly correlated\n",
    "    # ‘HV3’, ‘HV4’ - highly correlated\n",
    "    # ‘HV4’, ‘RP1’ - highly correlated\n",
    "\n",
    "    # We keep ‘HV1’ and ‘HV4’ which hold most information. Drop the others.\n",
    "\n",
    "    'HV2',\n",
    "    'HV3',\n",
    "    'HVP6',\n",
    "    'HVP2',\n",
    "    'RP1', \n",
    "\n",
    "    #====================\n",
    "    #====================\n",
    "\n",
    "    # ‘HU1’, # (“Percent Owner Occupied Units”)\n",
    "    # ‘HU2’, # (“Percent Renter Occupied Units”)\n",
    "\n",
    "    # ‘HU1’ and ‘HU2’ are highly correlated. \n",
    "\n",
    "    # Keep ‘HU1’ that hold higher variance.\n",
    "\n",
    "    'HU2',\n",
    "\n",
    "    #====================\n",
    "    #====================\n",
    "\n",
    "    # ‘HHD1’, # (“Percent Households w/ Related Children”)\n",
    "    # ‘HHD2’, # (“Percent Households w/ Families”)\n",
    "    # ‘HHD3’, # (“Percent Married Couple Families”)\n",
    "    # ‘HHD4’, # (“Percent Married Couple w/ Related Children”)\n",
    "    # ‘HHD5’, # (“Percent Persons in Family Household”)\n",
    "    # ‘HHD7’, # (“Percent Single Parent Household”)\n",
    "    # ‘HHD9’, # (“Percent Female Householder w/ Children”)\n",
    "    # ‘HHD11’, # (“Percent Single Female Householder”)\n",
    "    # ‘HHN1’, # (\"Percent 1 Person Households\")\n",
    "    # ‘AGE907’, # (“Percent Population Under Age 18”)\n",
    "    # ‘MARR1’, # (“Percent Married”)\n",
    "    # ‘HHN3’, # (“Percent Married”)\n",
    "\n",
    "    # ‘HHD1’ and ‘AGE907’ are highly correlated\n",
    "    # ‘HHD3’ and ‘MARR1’ are highly correlated\n",
    "    # ‘HHD3’ and ‘HHD2’ are highly correlated\n",
    "    # ‘HHD5’ and ‘HHD2’ are highly correlated\n",
    "    # ‘HHD4’ and ‘HHN3’ are highly correlated\n",
    "    # ‘HHD9’ and ‘HHD7’ are highly correlated\n",
    "    # ‘HHD11’ and ‘HHN1’ are highly correlated\n",
    "\n",
    "    # Drop ‘MARR1’,  ‘HHD5’, ‘AGE907’, ‘HHD9’, ‘HHN1’, ‘HHN3’\n",
    "\n",
    "    'HHD5',\n",
    "    'HHD9',\n",
    "    'HHN1',\n",
    "    'AGE907',\n",
    "    'MARR1',\n",
    "    'HHN3',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "\n",
    "    # ‘HV1’, # (“Median Home Value in hundreds”)\n",
    "    # ‘HV2’, # (“Average Home Value in hundreds”)\n",
    "    # ‘HVP1’, # (“Percent Home Value >= $ 200,000”)\n",
    "    # ‘HVP2’, # (“Percent Home Value >= $ 150,000”)\n",
    "    # ‘HVP4’, # (“Percent Home Value >= $ 75,000”)\n",
    "    # ‘HVP6’, # (“Percent Home Value >= $ 300,000”)\n",
    "\n",
    "    # ‘HV1’, ‘HVP1’, - highly correlated (keep 'HV1' because it has several correlations. Drop correlated)\n",
    "    # ‘HVP2’, ’HV2’ - highly correlated (Already dropped both)\n",
    "    # ‘HVP4’, ‘HVP3’ - highly correlated (Keep HVP3 because has higher variance)\n",
    "    # ‘HVP6’, ‘HV1’ - highly correlated (Drop HVP6)\n",
    "\n",
    "    # We keep ‘HV1’ and ‘HVP3’ which hold most information. Drop the others.\n",
    "\n",
    "    'HVP1',\n",
    "    'HVP4',\n",
    "    \n",
    "    #====================\n",
    "    #====================\n",
    "\n",
    "    # ‘RHP1’, # (“Median Number of Rooms per Housing Unit”)\n",
    "    # ‘RHP2’, # (“Average Number of Rooms per Housing Unit”)\n",
    "    # ‘RHP3’, # (“Median Number of Persons per Housing Unit”)\n",
    "    # ‘HUR2’, # (“Percent >= 6 Room Housing Units”)\n",
    "    # ‘HHN3’, # (“Percent Married”)\n",
    "\n",
    "    # Both 'RHP1' and 'RHP2' are highly correlated with 'HUR2'. Keep 'HUR2'\n",
    "    \n",
    "    # 'RHP3' AND 'HHN3' are highly correlated. Already dropped the latter. Keep 'RHP3'\n",
    "\n",
    "    # We keep ‘HUR2’ and ‘RHP3’ which hold most information. Drop the others.\n",
    "\n",
    "    'RHP1',\n",
    "    'RHP2',\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    ]\n",
    "\n",
    "# Ensure there are no duplicate values in the list\n",
    "to_drop = list(set(to_drop))\n",
    "\n",
    "print('Number of features to drop:', len(to_drop))\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the list of features created\n",
    "donors.drop(columns = to_drop, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of metric features before removal: 331\n",
      "Number of metric features afer removal: 249\n"
     ]
    }
   ],
   "source": [
    "# Update 'metric_features' list\n",
    "\n",
    "# Print the number of metric features before the removal\n",
    "print('Number of metric features before removal:', len(metric_features))\n",
    "\n",
    "# Get the features that are metric features and still exist in our dataset\n",
    "metric_features = list(set(metric_features) - set(to_drop))\n",
    "\n",
    "# And sort them according to our original order\n",
    "metric_features = sort_features(metric_features_orig, metric_features)\n",
    "\n",
    "# Print the number of metric features after the removal\n",
    "print('Number of metric features afer removal:', len(metric_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-metric features before removal: 47\n",
      "Number of non-metric features afer removal: 37\n"
     ]
    }
   ],
   "source": [
    "# Update 'non_metric_features' list\n",
    "\n",
    "# Print the number of metric features before the removal\n",
    "print('Number of non-metric features before removal:', len(non_metric_features))\n",
    "\n",
    "# Get the features that are metric features and still exist in our dataset\n",
    "non_metric_features = list(set(non_metric_features) - set(to_drop))\n",
    "\n",
    "# And sort them according to our original order\n",
    "non_metric_features = sort_features(non_metric_features_orig, non_metric_features)\n",
    "\n",
    "# Print the number of metric features after the removal\n",
    "print('Number of non-metric features afer removal:', len(non_metric_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95412, 286)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the actual shape of the data\n",
    "donors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert date features to numbers\n",
    "**The idea here is to use the value of 'ADATE_2' (Date the 17NK promotion was mailed) of every obersvation as reference date.**\n",
    "\n",
    "**The new values will be the number of days before the reference date. So for example DOB will be turned into the age in days relative to reference date.**\n",
    "\n",
    "**Additionally - for better understandability - all transformed columns are renamed to ......_rel_in_days**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies\n",
    "adate_2 = donors['ADATE_2'].copy()\n",
    "date_features_copy = date_features.copy()\n",
    "metric_features_copy = metric_features.copy()\n",
    "\n",
    "for feature in date_features:\n",
    "    \n",
    "    rel_time = adate_2 - donors[feature]\n",
    "    rel_time_days = rel_time.dt.days\n",
    "    donors[feature] = rel_time_days\n",
    "    \n",
    "    # Attach '_rel_in_days' to column name\n",
    "    new_col_name = feature + '_rel_in_days'\n",
    "    donors.rename(columns={feature : new_col_name}, inplace=True)\n",
    "    \n",
    "    # Update our lists 'metric_features' and 'date_features', Step 1\n",
    "    date_features_copy[date_features_copy.index(feature)] = new_col_name\n",
    "    metric_features_copy[metric_features_copy.index(feature)] = new_col_name\n",
    "    \n",
    "# Update our lists 'metric_features' and 'date_features', Step 2\n",
    "date_features = date_features_copy\n",
    "metric_features = metric_features_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        609.0\n",
       "1        609.0\n",
       "2          NaN\n",
       "3          NaN\n",
       "4        609.0\n",
       "         ...  \n",
       "95407      NaN\n",
       "95408      NaN\n",
       "95409    609.0\n",
       "95410    609.0\n",
       "95411    578.0\n",
       "Name: ADATE_10_rel_in_days, Length: 95412, dtype: float64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors['ADATE_10_rel_in_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "95407    0\n",
       "95408    0\n",
       "95409    0\n",
       "95410    0\n",
       "95411    0\n",
       "Name: ADATE_2_rel_in_days, Length: 95412, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors['ADATE_2_rel_in_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW_rel_in_days</th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>DOB_rel_in_days</th>\n",
       "      <th>MDMAUD</th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>HOMEOWNR</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>...</th>\n",
       "      <th>NEXTDATE_rel_in_days</th>\n",
       "      <th>TIMELAG</th>\n",
       "      <th>AVGGIFT</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>GEOCODE2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3073</td>\n",
       "      <td>GRI</td>\n",
       "      <td>IL</td>\n",
       "      <td>61081</td>\n",
       "      <td>21732.0</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>T2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>2649.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.741935</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1247</td>\n",
       "      <td>BOA</td>\n",
       "      <td>CA</td>\n",
       "      <td>91326</td>\n",
       "      <td>16557.0</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>S1</td>\n",
       "      <td>H</td>\n",
       "      <td>6.0</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>792.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>G</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2708</td>\n",
       "      <td>AMH</td>\n",
       "      <td>NC</td>\n",
       "      <td>27017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>R2</td>\n",
       "      <td>U</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>2343.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.481481</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ODATEDW_rel_in_days OSOURCE STATE    ZIP  DOB_rel_in_days MDMAUD DOMAIN  \\\n",
       "0                 3073     GRI    IL  61081          21732.0   XXXX     T2   \n",
       "1                 1247     BOA    CA  91326          16557.0   XXXX     S1   \n",
       "2                 2708     AMH    NC  27017              NaN   XXXX     R2   \n",
       "\n",
       "  HOMEOWNR  INCOME GENDER  ...  NEXTDATE_rel_in_days TIMELAG    AVGGIFT  \\\n",
       "0      NaN     NaN      F  ...                2649.0     4.0   7.741935   \n",
       "1        H     6.0      M  ...                 792.0    18.0  15.666667   \n",
       "2        U     3.0      M  ...                2343.0    12.0   7.481481   \n",
       "\n",
       "   HPHONE_D  RFA_2F  RFA_2A  MDMAUD_R  MDMAUD_F  MDMAUD_A  GEOCODE2  \n",
       "0         0       4       E         X         X         X         C  \n",
       "1         0       2       G         X         X         X         A  \n",
       "2         1       4       E         X         X         X         C  \n",
       "\n",
       "[3 rows x 286 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate GINI index to assess feature importance\n",
    "\n",
    "We will find which features have a GINI that can be considered low enough for the feature to be dropped.\n",
    "\n",
    "A first approach will contemplate the removal of features that have a GINI lower than half of the average values.\n",
    "\n",
    "The second will include a manually defined treshold as the lowest possible value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/oliviaguest/gini/blob/master/gini.py:\n",
    "\n",
    "def gini(array):\n",
    "    \"\"\"Calculate the Gini coefficient of a pandas series.\"\"\"\n",
    "    # based on bottom eq:\n",
    "    # http://www.statsdirect.com/help/generatedimages/equations/equation154.svg\n",
    "    # from:\n",
    "    # http://www.statsdirect.com/help/default.htm#nonparametric_methods/gini.htm\n",
    "    # All values are treated equally, arrays must be 1d:\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    array = array.values\n",
    "    \n",
    "    # Remove nan values before the calculation\n",
    "    array = array[np.logical_not(np.isnan(array))]\n",
    "    \n",
    "    # If int64, convert to float64\n",
    "    if array.dtype == 'int64':\n",
    "        array = np.float64(array)\n",
    "    \n",
    "    array = array.flatten()\n",
    "    if np.amin(array) < 0:\n",
    "        # Values cannot be negative:\n",
    "        array -= np.amin(array)\n",
    "    # Values cannot be 0:\n",
    "    array += 0.0000001\n",
    "    # Values must be sorted:\n",
    "    array = np.sort(array)\n",
    "    # Index per array element:\n",
    "    index = np.arange(1,array.shape[0]+1)\n",
    "    # Number of array elements:\n",
    "    n = array.shape[0]\n",
    "    # Gini coefficient:\n",
    "    return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features to drop using the average value is: 71\n",
      "The number of features to drop using the treshold is: 31\n"
     ]
    }
   ],
   "source": [
    "# Apply the function and get each feature's GINI\n",
    "\n",
    "# Define the treshold\n",
    "gini_limit = 0.1\n",
    "\n",
    "# Get the results in a list\n",
    "gini_coefficient = []\n",
    "for feature in list(donors[metric_features]):\n",
    "    gini_ = gini(donors[feature])\n",
    "    gini_coefficient.append(gini_)\n",
    "    \n",
    "# Store the results in a data frame    \n",
    "gini_coefficients = pd.DataFrame(data={'Feature': list(donors[metric_features]),\n",
    "                                       'Gini coefficient': gini_coefficient}).set_index('Feature').sort_values(by='Gini coefficient',\n",
    "                                                                                                               ascending=False)\n",
    "\n",
    "# Get those that have a GINI lower than half of the average GINI\n",
    "low_gini_average = gini_coefficients.loc[gini_coefficients['Gini coefficient'] < np.divide(gini_coefficients['Gini coefficient'].mean(), 2)]\n",
    "to_drop_gini_average = list(low_gini_average.index)\n",
    "\n",
    "# Get those that have a GINI lower than the treshold\n",
    "low_gini_treshold = gini_coefficients.loc[gini_coefficients['Gini coefficient'] < gini_limit]\n",
    "to_drop_gini_treshold = list(low_gini_treshold.index)\n",
    "\n",
    "# Compare both list generated\n",
    "print('The number of features to drop using the average value is:', len(to_drop_gini_average))\n",
    "print('The number of features to drop using the treshold is:', len(to_drop_gini_treshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop one of the list of features\n",
    "donors.drop(columns = to_drop_gini_average, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of metric features before removal: 249\n",
      "Number of metric features afer removal: 173\n"
     ]
    }
   ],
   "source": [
    "# Update 'metric_features' list\n",
    "\n",
    "# Indicated the list that was used above\n",
    "list_used = to_drop_gini_average\n",
    "\n",
    "# Print the number of metric features before the removal\n",
    "print('Number of metric features before removal:', len(metric_features))\n",
    "\n",
    "# Get the features that are metric features and still exist in our dataset\n",
    "metric_features = list(set(metric_features) - set(list_used))\n",
    "\n",
    "# And sort them according to our original order\n",
    "metric_features = sort_features(metric_features_orig, metric_features)\n",
    "\n",
    "# Print the number of metric features after the removal\n",
    "print('Number of metric features afer removal:', len(metric_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose perspectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treat outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95412, 215)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCOME</th>\n",
       "      <th>HIT</th>\n",
       "      <th>MALEMILI</th>\n",
       "      <th>MALEVET</th>\n",
       "      <th>VIETVETS</th>\n",
       "      <th>WWIIVETS</th>\n",
       "      <th>LOCALGOV</th>\n",
       "      <th>STATEGOV</th>\n",
       "      <th>FEDGOV</th>\n",
       "      <th>POP901</th>\n",
       "      <th>...</th>\n",
       "      <th>AC1</th>\n",
       "      <th>AC2</th>\n",
       "      <th>NUMPROM</th>\n",
       "      <th>RAMNTALL</th>\n",
       "      <th>NGIFTALL</th>\n",
       "      <th>MINRAMNT</th>\n",
       "      <th>MAXRAMNT</th>\n",
       "      <th>LASTGIFT</th>\n",
       "      <th>TIMELAG</th>\n",
       "      <th>AVGGIFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>992</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>240.0</td>\n",
       "      <td>31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.741935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3611</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>18172</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1067</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>107.0</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2607</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95406</th>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>46</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1834</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "      <td>81.0</td>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95407</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>27380</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95408</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1254</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95409</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>552</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95410</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1746</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>498.0</td>\n",
       "      <td>41</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.146341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52372 rows × 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       INCOME  HIT  MALEMILI  MALEVET  VIETVETS  WWIIVETS  LOCALGOV  STATEGOV  \\\n",
       "0         NaN    0         0       39        34        18        10         2   \n",
       "1         6.0   16         0       15        55        11         6         2   \n",
       "5         NaN    0         0       26        36        23         7         5   \n",
       "6         4.0    0         0       33        36        34         7         1   \n",
       "9         NaN    0         0       28        51        14         5         2   \n",
       "...       ...  ...       ...      ...       ...       ...       ...       ...   \n",
       "95406     6.0   10         2       44        26        46        25         9   \n",
       "95407     NaN    0        14       36        47        11         7         8   \n",
       "95408     7.0    1         0       31        43        19         4         1   \n",
       "95409     NaN    0         0       18        46        20         7        23   \n",
       "95410     7.0    0         0       28        35        20         9         1   \n",
       "\n",
       "       FEDGOV  POP901  ...  AC1  AC2  NUMPROM  RAMNTALL  NGIFTALL  MINRAMNT  \\\n",
       "0           1     992  ...   10    7       74     240.0        31       5.0   \n",
       "1           1    3611  ...    6    5       32      47.0         3      10.0   \n",
       "5           6   18172  ...    6    4       35      51.0         4      10.0   \n",
       "6           1    1067  ...    3    4       63     107.0        14       3.0   \n",
       "9           2    2607  ...    8    9       28      28.0         3       3.0   \n",
       "...       ...     ...  ...  ...  ...      ...       ...       ...       ...   \n",
       "95406       1    1834  ...    5    8       59      81.0        24       2.0   \n",
       "95407      13   27380  ...    4    3       14      25.0         1      25.0   \n",
       "95408       0    1254  ...    3    2       10      20.0         1      20.0   \n",
       "95409       0     552  ...    3   11       33      58.0         7       3.0   \n",
       "95410       1    1746  ...    6    3      127     498.0        41       5.0   \n",
       "\n",
       "       MAXRAMNT  LASTGIFT  TIMELAG    AVGGIFT  \n",
       "0          12.0      10.0      4.0   7.741935  \n",
       "1          25.0      25.0     18.0  15.666667  \n",
       "5          16.0      15.0      6.0  12.750000  \n",
       "6          12.0      11.0      4.0   7.642857  \n",
       "9          15.0      15.0      7.0   9.333333  \n",
       "...         ...       ...      ...        ...  \n",
       "95406       9.0       2.0      3.0   3.375000  \n",
       "95407      25.0      25.0      NaN  25.000000  \n",
       "95408      20.0      20.0      NaN  20.000000  \n",
       "95409      10.0      10.0      3.0   8.285714  \n",
       "95410      21.0      18.0      4.0  12.146341  \n",
       "\n",
       "[52372 rows x 173 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find Nan values before the outlier removal\n",
    "nans_index = donors[metric_features].isna().any(axis=1)\n",
    "donors[metric_features][nans_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNImputer - only works for numerical variables\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "donors[metric_features] = imputer.fit_transform(donors[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCOME</th>\n",
       "      <th>HIT</th>\n",
       "      <th>MALEMILI</th>\n",
       "      <th>MALEVET</th>\n",
       "      <th>VIETVETS</th>\n",
       "      <th>WWIIVETS</th>\n",
       "      <th>LOCALGOV</th>\n",
       "      <th>STATEGOV</th>\n",
       "      <th>FEDGOV</th>\n",
       "      <th>POP901</th>\n",
       "      <th>...</th>\n",
       "      <th>AC1</th>\n",
       "      <th>AC2</th>\n",
       "      <th>NUMPROM</th>\n",
       "      <th>RAMNTALL</th>\n",
       "      <th>NGIFTALL</th>\n",
       "      <th>MINRAMNT</th>\n",
       "      <th>MAXRAMNT</th>\n",
       "      <th>LASTGIFT</th>\n",
       "      <th>TIMELAG</th>\n",
       "      <th>AVGGIFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>992.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.741935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95406</th>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1834.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95407</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27380.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95408</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95409</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95410</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.146341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52372 rows × 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       INCOME   HIT  MALEMILI  MALEVET  VIETVETS  WWIIVETS  LOCALGOV  \\\n",
       "0         2.0   0.0       0.0     39.0      34.0      18.0      10.0   \n",
       "1         6.0  16.0       0.0     15.0      55.0      11.0       6.0   \n",
       "5         4.0   0.0       0.0     26.0      36.0      23.0       7.0   \n",
       "6         4.0   0.0       0.0     33.0      36.0      34.0       7.0   \n",
       "9         3.0   0.0       0.0     28.0      51.0      14.0       5.0   \n",
       "...       ...   ...       ...      ...       ...       ...       ...   \n",
       "95406     6.0  10.0       2.0     44.0      26.0      46.0      25.0   \n",
       "95407     6.4   0.0      14.0     36.0      47.0      11.0       7.0   \n",
       "95408     7.0   1.0       0.0     31.0      43.0      19.0       4.0   \n",
       "95409     3.0   0.0       0.0     18.0      46.0      20.0       7.0   \n",
       "95410     7.0   0.0       0.0     28.0      35.0      20.0       9.0   \n",
       "\n",
       "       STATEGOV  FEDGOV   POP901  ...   AC1   AC2  NUMPROM  RAMNTALL  \\\n",
       "0           2.0     1.0    992.0  ...  10.0   7.0     74.0     240.0   \n",
       "1           2.0     1.0   3611.0  ...   6.0   5.0     32.0      47.0   \n",
       "5           5.0     6.0  18172.0  ...   6.0   4.0     35.0      51.0   \n",
       "6           1.0     1.0   1067.0  ...   3.0   4.0     63.0     107.0   \n",
       "9           2.0     2.0   2607.0  ...   8.0   9.0     28.0      28.0   \n",
       "...         ...     ...      ...  ...   ...   ...      ...       ...   \n",
       "95406       9.0     1.0   1834.0  ...   5.0   8.0     59.0      81.0   \n",
       "95407       8.0    13.0  27380.0  ...   4.0   3.0     14.0      25.0   \n",
       "95408       1.0     0.0   1254.0  ...   3.0   2.0     10.0      20.0   \n",
       "95409      23.0     0.0    552.0  ...   3.0  11.0     33.0      58.0   \n",
       "95410       1.0     1.0   1746.0  ...   6.0   3.0    127.0     498.0   \n",
       "\n",
       "       NGIFTALL  MINRAMNT  MAXRAMNT  LASTGIFT  TIMELAG    AVGGIFT  \n",
       "0          31.0       5.0      12.0      10.0      4.0   7.741935  \n",
       "1           3.0      10.0      25.0      25.0     18.0  15.666667  \n",
       "5           4.0      10.0      16.0      15.0      6.0  12.750000  \n",
       "6          14.0       3.0      12.0      11.0      4.0   7.642857  \n",
       "9           3.0       3.0      15.0      15.0      7.0   9.333333  \n",
       "...         ...       ...       ...       ...      ...        ...  \n",
       "95406      24.0       2.0       9.0       2.0      3.0   3.375000  \n",
       "95407       1.0      25.0      25.0      25.0      9.8  25.000000  \n",
       "95408       1.0      20.0      20.0      20.0     11.8  20.000000  \n",
       "95409       7.0       3.0      10.0      10.0      3.0   8.285714  \n",
       "95410      41.0       5.0      21.0      18.0      4.0  12.146341  \n",
       "\n",
       "[52372 rows x 173 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors[metric_features][nans_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors.to_csv(path_or_buf='donors_after_KNN_imputation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    donors = pd.read_csv('donors_after_KNN_imputation.csv')\n",
    "    donors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('donors_after_KNN_imputation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the changes\n",
    "donors[metric_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Data Mining Lab 11\n",
    "\n",
    "# K-distance graph to find out the right eps value\n",
    "neigh = NearestNeighbors(n_neighbors = 200) # Value of k is approximately sqrt(n_rows)\n",
    "neigh.fit(donors[metric_features])\n",
    "distances, _ = neigh.kneighbors(donors[metric_features])\n",
    "distances = np.sort(distances[:, -1])\n",
    "plt.plot(distances)\n",
    "plt.ylabel(\"distance to the kth (k = minPts - 1) nearest neighbor\")\n",
    "plt.xlabel(\"Objects\")\n",
    "plt.ylim((0,1250))\n",
    "plt.title(\"Find optimal value of eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing a conservative approach, eps is chosen as 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Data Mining Lab 11\n",
    "\n",
    "# Perform DBSCAN clustering\n",
    "dbscan = DBSCAN(eps = 500, min_samples = 300, n_jobs = -1)\n",
    "dbscan_labels = dbscan.fit_predict(donors[metric_features])\n",
    "\n",
    "dbscan_n_clusters = len(np.unique(dbscan_labels))\n",
    "print(\"Number of estimated clusters : %d\" % dbscan_n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the labels to donors\n",
    "dbscan_concat = pd.concat([donors, pd.Series(dbscan_labels, index=donors.index, name=\"dbscan_labels\")], axis=1)\n",
    "dbscan_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dbscan_concat.dbscan_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Detecting noise (potential outliers)\n",
    "noise_points = dbscan_concat.loc[dbscan_concat['dbscan_labels'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number and share of points that are considered to pe possible outliers\n",
    "outliers_dbscan = noise_points.shape[0]\n",
    "total_points = donors.shape[0]\n",
    "outliers_share_dbscan = round(np.divide(outliers_dbscan, total_points), 4) * 100\n",
    "print('The percentage of data to remove is:', outliers_share_dbscan, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index\n",
    "index_donors = list(donors.index)\n",
    "\n",
    "# Get noise_points index\n",
    "index_noise = list(noise_points.index)\n",
    "\n",
    "# Get the values in donors and not in noise\n",
    "new_index = list(set(index_donors) - set(index_noise))\n",
    "\n",
    "# Remove from original dataframe the observations that are in the noise dataframe\n",
    "donors = donors.iloc[new_index]\n",
    "\n",
    "# Get the new shape\n",
    "donors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataset\n",
    "data_to_scale = donors[metric_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MinMaxScaler to scale the data\n",
    "scaler = StandardScaler()\n",
    "scaled_feat = scaler.fit_transform(data_to_scale)\n",
    "scaled_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assign the changes\n",
    "donors[metric_features] = scaled_feat\n",
    "donors.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(donors[metric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping variables by categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remaining metric features\n",
    "\n",
    "        # Below: Information about the donor\n",
    "['ODATEDW_rel_in_days',\n",
    " 'DOB_rel_in_days',\n",
    " 'INCOME',\n",
    " 'HIT',\n",
    "\n",
    "        # Below: Data from third party regarding the household or neighborhood (According to David Silva) \n",
    " 'MALEMILI',\n",
    " 'MALEVET',\n",
    " 'VIETVETS',\n",
    " 'WWIIVETS',\n",
    " 'LOCALGOV',\n",
    " 'STATEGOV',\n",
    " 'FEDGOV',\n",
    "    # Below: About donor's neighbourhood\n",
    "        # Population\n",
    " 'POP901',\n",
    " 'POP90C1',\n",
    " 'POP90C2',\n",
    " 'POP90C3',\n",
    "        # Provenance\n",
    " 'ETH2',\n",
    " 'ETH3',\n",
    " 'ETH4',\n",
    " 'ETH5',\n",
    " 'ETH6',\n",
    " 'ETH7',\n",
    " 'ETH8',\n",
    " 'ETH9',\n",
    " 'ETH10',\n",
    " 'ETH14',\n",
    " 'ETH16',\n",
    "        # Ages \n",
    " 'AGEC1',\n",
    " 'AGEC7',\n",
    " 'AC1',\n",
    " 'AC2',\n",
    "        # Household occupation\n",
    " 'HHN5',\n",
    "        # Marrital status\n",
    " 'MARR2',\n",
    "        # Housing type\n",
    " 'DW2',\n",
    " 'DW3',\n",
    " 'DW4',\n",
    " 'DW7',\n",
    " 'DW9',\n",
    "        # Housing price\n",
    " 'HV1',\n",
    "        # Household quantity\n",
    " 'HU4',\n",
    " 'HU5',\n",
    "        # Household people held\n",
    " 'HHD4',\n",
    " 'HHD6',\n",
    " 'HHD7',\n",
    " 'HHD8',\n",
    " 'HHD10',\n",
    " 'HHD11',\n",
    " 'HHD12',\n",
    "        # Provenance and respective age\n",
    " 'ETHC1',\n",
    " 'ETHC3',\n",
    " 'ETHC6',\n",
    "        # Housing price\n",
    " 'HVP3',\n",
    " 'HVP5',\n",
    " 'HUR1',\n",
    " 'HUR2',\n",
    " 'HUPA1',\n",
    " 'HUPA3',\n",
    " 'HUPA4',\n",
    " 'HUPA5',\n",
    " 'HUPA7',\n",
    " 'RP3',\n",
    "        # Income\n",
    " 'IC2',\n",
    " 'IC6',\n",
    " 'IC19',\n",
    "        # Housing and wealth\n",
    " 'HHAS1',\n",
    " 'HHAS2',\n",
    " 'HHAS3',\n",
    " 'HHAS4',\n",
    "        # House moving\n",
    " 'MC3',\n",
    "        # Way to work (time taken)\n",
    " 'TPE2',\n",
    " 'TPE3',\n",
    " 'TPE5',\n",
    " 'TPE6',\n",
    " 'TPE7',\n",
    " 'TPE8',\n",
    " 'TPE9',\n",
    " 'PEC1',\n",
    " 'PEC2',\n",
    " 'TPE12',\n",
    "        # Labor force ??\n",
    " 'LFC10',\n",
    "        # Life occupation\n",
    " 'OCC1',\n",
    " 'OCC2',\n",
    " 'OCC3',\n",
    " 'OCC4',\n",
    " 'OCC5',\n",
    " 'OCC6',\n",
    " 'OCC7',\n",
    " 'OCC8',\n",
    " 'OCC10',\n",
    " 'OCC11',\n",
    " 'OCC12',\n",
    " 'OCC13',\n",
    "        # Job\n",
    " 'EIC1',\n",
    " 'EIC2',\n",
    " 'EIC3',\n",
    " 'EIC4',\n",
    " 'EIC5',\n",
    " 'EIC6',\n",
    " 'EIC7',\n",
    " 'EIC8',\n",
    " 'EIC9',\n",
    " 'EIC10',\n",
    " 'EIC11',\n",
    " 'EIC12',\n",
    " 'EIC13',\n",
    " 'EIC14',\n",
    " 'EIC15',\n",
    " 'EIC16',\n",
    " 'OEDC1',\n",
    " 'OEDC2',\n",
    " 'OEDC3',\n",
    " 'OEDC4',\n",
    " 'OEDC6',\n",
    " 'OEDC7',\n",
    "        # Education\n",
    " 'EC2',\n",
    " 'EC3',\n",
    " 'EC4',\n",
    " 'EC6',\n",
    " 'EC7',\n",
    " 'EC8',\n",
    " 'SEC1',\n",
    " 'SEC3',\n",
    " 'SEC4',\n",
    " 'SEC5',\n",
    "        # Military service\n",
    " 'AFC2',\n",
    " 'AFC3',\n",
    " 'AFC6',\n",
    " 'VC1',\n",
    " 'VC2',\n",
    " 'VC3',\n",
    " 'VC4',\n",
    "        # Nationality / Language\n",
    " 'ANC1',\n",
    " 'ANC2',\n",
    " 'ANC3',\n",
    " 'ANC4',\n",
    " 'ANC5',\n",
    " 'ANC6',\n",
    " 'ANC7',\n",
    " 'ANC8',\n",
    " 'ANC9',\n",
    " 'ANC10',\n",
    " 'ANC11',\n",
    " 'ANC12',\n",
    " 'ANC13',\n",
    " 'ANC14',\n",
    " 'ANC15',\n",
    " 'POBC1',\n",
    " 'POBC2',\n",
    " 'LSC3',\n",
    " 'LSC4',\n",
    "        # Vehicle Possession\n",
    " 'VOC3',\n",
    "        # Housing Facilities\n",
    " 'HC1',\n",
    " 'HC2',\n",
    " 'HC3',\n",
    " 'HC4',\n",
    " 'HC5',\n",
    " 'HC6',\n",
    " 'HC8',\n",
    " 'HC9',\n",
    " 'HC10',\n",
    " 'HC11',\n",
    " 'HC12',\n",
    " 'HC13',\n",
    " 'HC14',\n",
    " 'HC15',\n",
    " 'HC16',\n",
    " 'HC19',\n",
    "        # Mortage\n",
    " 'MHUC1',\n",
    "        # Above: About donor's neighbourhood      \n",
    "        # Below: Date promotion X was mailed\n",
    " # 'ADATE_2_rel_in_days',\n",
    " # 'ADATE_3_rel_in_days',\n",
    " # 'ADATE_4_rel_in_days',\n",
    " # 'ADATE_5_rel_in_days',\n",
    " # 'ADATE_6_rel_in_days',\n",
    " # 'ADATE_7_rel_in_days',\n",
    " # 'ADATE_8_rel_in_days',\n",
    " # 'ADATE_9_rel_in_days',\n",
    " # 'ADATE_10_rel_in_days',\n",
    " # 'ADATE_11_rel_in_days',\n",
    " # 'ADATE_12_rel_in_days',\n",
    " # 'ADATE_14_rel_in_days',\n",
    " # 'ADATE_16_rel_in_days',\n",
    " # 'ADATE_17_rel_in_days',\n",
    " # 'ADATE_18_rel_in_days',\n",
    " # 'ADATE_19_rel_in_days',\n",
    " # 'ADATE_21_rel_in_days',\n",
    " # 'ADATE_22_rel_in_days',\n",
    " # 'ADATE_24_rel_in_days',\n",
    " # 'MAXADATE_rel_in_days',\n",
    "        # Below: Information about how many promotions donor has received\n",
    " 'NUMPROM',\n",
    " # 'CARDPM12', (removed)\n",
    " # 'NUMPRM12', (removed)\n",
    "        # Below: Summary variables for this donor\n",
    " 'RAMNTALL',\n",
    " 'NGIFTALL',\n",
    " 'MINRAMNT',\n",
    " # 'MINRDATE_rel_in_days', (removed)\n",
    " 'MAXRAMNT',\n",
    " # 'MAXRDATE_rel_in_days', (removed)\n",
    " 'LASTGIFT',\n",
    " # 'LASTDATE_rel_in_days', (removed)\n",
    " # 'FISTDATE_rel_in_days', (removed)\n",
    " # 'NEXTDATE_rel_in_days', (removed)\n",
    " 'TIMELAG',\n",
    " 'AVGGIFT']\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about the donor\n",
    "gini_coefficients.loc[\n",
    "    ['ODATEDW_rel_in_days',\n",
    " 'DOB_rel_in_days',\n",
    " 'INCOME',\n",
    " 'HIT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about how many promotions donor has received\n",
    "gini_coefficients.loc[\n",
    "    ['NUMPROM',\n",
    " 'CARDPM12',\n",
    " 'NUMPRM12']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary variables for this donor\n",
    "gini_coefficients.loc[\n",
    "    ['RAMNTALL',\n",
    " 'NGIFTALL',\n",
    " 'MINRAMNT',\n",
    " 'MINRDATE_rel_in_days',\n",
    " 'MAXRAMNT',\n",
    " 'MAXRDATE_rel_in_days',\n",
    " 'LASTGIFT',\n",
    " 'LASTDATE_rel_in_days',\n",
    " 'FISTDATE_rel_in_days',\n",
    " 'NEXTDATE_rel_in_days',\n",
    " 'TIMELAG',\n",
    " 'AVGGIFT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_coefficients.loc[\n",
    "['MALEMILI',\n",
    " 'MALEVET',\n",
    " 'VIETVETS',\n",
    " 'WWIIVETS',\n",
    " 'LOCALGOV',\n",
    " 'STATEGOV',\n",
    " 'FEDGOV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini(donors.LOCALGOV + donors.STATEGOV + donors.FEDGOV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(donors.LOCALGOV + donors.STATEGOV + donors.FEDGOV).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighborhood Population\n",
    "\n",
    "nb_population_features = ['POP901',\n",
    "                         'POP90C1',\n",
    "                         'POP90C2',\n",
    "                         'POP90C3'\n",
    "                         ]\n",
    "donors_nb_population = donors[nb_population_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighborhood Provenance\n",
    "\n",
    "nb_provenance_features = ['ETH2',\n",
    "                         'ETH3',\n",
    "                         'ETH4',\n",
    "                         'ETH5',\n",
    "                         'ETH6',\n",
    "                         'ETH7',\n",
    "                         'ETH8',\n",
    "                         'ETH9',\n",
    "                         'ETH10',\n",
    "                         'ETH14',\n",
    "                         'ETH16'\n",
    "                         ]\n",
    "donors_nb_provenance = donors[nb_provenance_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighborhood Ages\n",
    "\n",
    "nb_ages_features = ['AGEC1',\n",
    "                    'AGEC7',\n",
    "                    'AC1',\n",
    "                    'AC2'\n",
    "                   ]\n",
    "\n",
    "donors_nb_ages = donors[nb_ages_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighborhood House Occupation\n",
    "\n",
    "nb_house_occu_features = ['HHN5']\n",
    "\n",
    "donors_nb_house_occu = donors[nb_house_occu_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighborhood Marital Status\n",
    "\n",
    "nb_marital_status_features = ['MARR2']\n",
    "                   \n",
    "\n",
    "donors_nb_marital_status = donors[nb_marital_status_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighborhood Housing Type\n",
    "\n",
    "nb_housing_type_features = ['DW2',\n",
    "                            'DW3',\n",
    "                            'DW4',\n",
    "                            'DW7',\n",
    "                            'DW9'\n",
    "                           ]\n",
    "\n",
    "donors_nb_housing_type = donors[nb_housing_type_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighborhood Housing price\n",
    "\n",
    "nb_housing_price_features = ['HV1',\n",
    "                             'HVP3',\n",
    "                             'HVP5',\n",
    "                             'HUR1',\n",
    "                             'HUR2',\n",
    "                             'HUPA1',\n",
    "                             'HUPA3',\n",
    "                             'HUPA4',\n",
    "                             'HUPA5',\n",
    "                             'HUPA7',\n",
    "                             'RP3'\n",
    "                            ]\n",
    "                   \n",
    "\n",
    "donors_nb_housing_price = donors[nb_housing_price_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Household quantity\n",
    "\n",
    "nb_housing_quantity_features = ['HU4', \n",
    "                                'HU5'\n",
    "                               ]\n",
    "\n",
    "donors_nb_housing_quantity = donors[nb_housing_quantity_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Household people held\n",
    "\n",
    "nb_people_held_features = ['HHD4',\n",
    "                            'HHD6',\n",
    "                            'HHD7',\n",
    "                            'HHD8',\n",
    "                            'HHD10',\n",
    "                            'HHD11',\n",
    "                            'HHD12'\n",
    "                           ]\n",
    "\n",
    "donors_nb_people_held = donors[nb_people_held_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provenance and respective age\n",
    "\n",
    "nb_provenance_and_age_features = ['ETHC1', \n",
    "                                  'ETHC3',\n",
    "                                  'ETHC6'\n",
    "                                 ]\n",
    "\n",
    "donors_nb_provenance_and_age = donors[nb_provenance_and_age_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Household people held\n",
    "\n",
    "nb_people_held_features = ['HHD4',\n",
    "                            'HHD6',\n",
    "                            'HHD7',\n",
    "                            'HHD8',\n",
    "                            'HHD10',\n",
    "                            'HHD11',\n",
    "                            'HHD12'\n",
    "                           ]\n",
    "\n",
    "donors_nb_people_held = donors[nb_people_held_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income\n",
    "\n",
    "nb_income_features = ['HHD4',\n",
    "                      'IC2',\n",
    "                      'IC6',\n",
    "                      'IC19'\n",
    "                    ]\n",
    "\n",
    "donors_nb_income = donors[nb_income_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housing and wealth\n",
    "\n",
    "nb_housing_and_wealth_features = ['HHAS1',\n",
    "                                 'HHAS2',\n",
    "                                 'HHAS3',\n",
    "                                 'HHAS4'\n",
    "                                ]\n",
    "\n",
    "donors_nb_housing_and_wealth = donors[nb_housing_and_wealth_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# House moving\n",
    "\n",
    "nb_house_moving_features = ['MC3']\n",
    "\n",
    "donors_nb_house_moving = donors[nb_house_moving_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Way to work (time taken)\n",
    "\n",
    "nb_way_to_work_features = ['TPE2',\n",
    "                         'TPE3',\n",
    "                         'TPE5',\n",
    "                         'TPE6',\n",
    "                         'TPE7',\n",
    "                         'TPE8',\n",
    "                         'TPE9',\n",
    "                         'PEC1',\n",
    "                         'PEC2',\n",
    "                         'TPE12'\n",
    "                        ]\n",
    "\n",
    "donors_nb_way_to_work = donors[nb_way_to_work_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labor force ??\n",
    "\n",
    "nb_labor_force_features = ['LFC10']\n",
    "\n",
    "donors_nb_labor_force = donors[nb_labor_force_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Life occupation\n",
    "\n",
    "nb_life_occu_features = ['OCC1',\n",
    "                         'OCC2',\n",
    "                         'OCC3',\n",
    "                         'OCC4',\n",
    "                         'OCC5',\n",
    "                         'OCC6',\n",
    "                         'OCC7',\n",
    "                         'OCC8',\n",
    "                         'OCC10',\n",
    "                         'OCC11',\n",
    "                         'OCC12',\n",
    "                         'OCC13'\n",
    "                        ]\n",
    "\n",
    "donors_nb_life_occu = donors[nb_life_occu_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job\n",
    "\n",
    "nb_job_features = ['EIC1',\n",
    "                 'EIC2',\n",
    "                 'EIC3',\n",
    "                 'EIC4',\n",
    "                 'EIC5',\n",
    "                 'EIC6',\n",
    "                 'EIC7',\n",
    "                 'EIC8',\n",
    "                 'EIC9',\n",
    "                 'EIC10',\n",
    "                 'EIC11',\n",
    "                 'EIC12',\n",
    "                 'EIC13',\n",
    "                 'EIC14',\n",
    "                 'EIC15',\n",
    "                 'EIC16',\n",
    "                 'OEDC1',\n",
    "                 'OEDC2',\n",
    "                 'OEDC3',\n",
    "                 'OEDC4',\n",
    "                 'OEDC6',\n",
    "                 'OEDC7'\n",
    "                  ]\n",
    "\n",
    "donors_nb_job = donors[nb_job_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education\n",
    "\n",
    "nb_education_features = ['EC2',\n",
    "                 'EC3',\n",
    "                 'EC4',\n",
    "                 'EC6',\n",
    "                 'EC7',\n",
    "                 'EC8',\n",
    "                 'SEC1',\n",
    "                 'SEC3',\n",
    "                 'SEC4',\n",
    "                 'SEC5'\n",
    "                  ]\n",
    "\n",
    "donors_nb_education = donors[nb_education_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Military Service\n",
    "\n",
    "nb_military_service_features = ['AFC2',\n",
    "                         'AFC3',\n",
    "                         'AFC6',\n",
    "                         'VC1',\n",
    "                         'VC2',\n",
    "                         'VC3',\n",
    "                         'VC4'\n",
    "                        ]\n",
    "\n",
    "donors_nb_military_service = donors[nb_military_service_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nationality\n",
    "\n",
    "nb_nationality_features = ['ANC1',\n",
    "                         'ANC2',\n",
    "                         'ANC3',\n",
    "                         'ANC4',\n",
    "                         'ANC5',\n",
    "                         'ANC6',\n",
    "                         'ANC7',\n",
    "                         'ANC8',\n",
    "                         'ANC9',\n",
    "                         'ANC10',\n",
    "                         'ANC11',\n",
    "                         'ANC12',\n",
    "                         'ANC13',\n",
    "                         'ANC14',\n",
    "                         'ANC15',\n",
    "                         'POBC1',\n",
    "                         'POBC2',\n",
    "                         'LSC3',\n",
    "                         'LSC4'\n",
    "                        ]\n",
    "\n",
    "donors_nb_nationality = donors[nb_nationality_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicle Possesion\n",
    "\n",
    "nb_vehicle_poss_features = ['VOC3']\n",
    "\n",
    "donors_nb_vehicle_poss = donors[nb_vehicle_poss_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housing Facilities\n",
    "\n",
    "nb_housing_facilities_features = ['HC1',\n",
    "                                 'HC2',\n",
    "                                 'HC3',\n",
    "                                 'HC4',\n",
    "                                 'HC5',\n",
    "                                 'HC6',\n",
    "                                 'HC8',\n",
    "                                 'HC9',\n",
    "                                 'HC10',\n",
    "                                 'HC11',\n",
    "                                 'HC12',\n",
    "                                 'HC13',\n",
    "                                 'HC14',\n",
    "                                 'HC15',\n",
    "                                 'HC16',\n",
    "                                 'HC19'\n",
    "                            ]\n",
    "\n",
    "donors_nb_housing_facilities = donors[nb_housing_facilities_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mortage\n",
    "\n",
    "nb_mortage_features = ['MHUC1']\n",
    "\n",
    "donors_nb_mortage = donors[nb_mortage_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st clustering perspective: Info on individual and individual's potential motivation for donation \n",
    "# (affiliation to military and governmentand)\n",
    "\n",
    "if False:\n",
    "    donors.ODATEDW_rel_in_days # Origin Date. Date of donor's first gift\n",
    "    donors.INCOME # HOUSEHOLD INCOME\n",
    "    donors.MALEMILI\n",
    "    donors.MALEVET\n",
    "    donors.LOCALGOV+donors.STATEGOV+donors.FEDGOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd clustering perspective: Individual's donation behaviour\n",
    "\n",
    "if False:\n",
    "    donors.NUMPROM # Lifetime number of promotions received to date\n",
    "    donors.RAMNTALL # Dollar amount of lifetime gifts to date\n",
    "    donors.NGIFTALL # Number of lifetime gifts to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective_1 = [\n",
    "    # 'ODATEDW_rel_in_days', # Origin Date. Date of donor's first gift (COMMENTING THIS BECAUSE THIS FEATURE WAS REMOVED)\n",
    "    'INCOME', # HOUSEHOLD INCOME\n",
    "    'MALEMILI', # % Males active in the Military\n",
    "    'MALEVET', # % Males Veterans\n",
    "    'GOV' # Sum of (% Employed by Local Gov, % Employed by State Gov, % Employed by Fed Gov)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective_2 = [    \n",
    "    'NUMPROM', # Lifetime number of promotions received to date\n",
    "    'RAMNTALL', # Dollar amount of lifetime gifts to date\n",
    "    'NGIFTALL' # Number of lifetime gifts to date\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspectives_1_2 = perspective_1 + perspective_2\n",
    "perspectives_1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create (donors.LOCALGOV + donors.STATEGOV + donors.FEDGOV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors['GOV'] = (donors.LOCALGOV + donors.STATEGOV + donors.FEDGOV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying to cluster for population variables\n",
    "\n",
    "Since we have around 100 000 observations, HC can reveal to be unsuitable. Because of this we will run KMeans with k = 150 firstly and apply HC on top of those results.\n",
    "\n",
    "We will still try to cluster by prespectives in a first approach in order to keep as much info as possible.\n",
    "\n",
    "WATCH OUT, NEGATIVE VALUES IN PERCENTAGE COLUMNS!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KMeans\n",
    "kmeans = KMeans(n_clusters = 150,\n",
    "                 init = 'k-means++',\n",
    "                 n_init = 10, # number of times KMeans is initialized \n",
    "                 random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING THE IDEA WITH POPULATION. THE IDEA IS TO THEN DO A FOR WITH ALL THE DATASETS PRESPECTIVES AND CLUSTER EACH ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for population\n",
    "kmeans_labels = kmeans.fit_predict(donors_nb_population)\n",
    "kmeans_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the final clusters\n",
    "df_concat_pop = pd.concat((donors_nb_population, pd.Series(kmeans_labels, name='labels')), axis=1)\n",
    "df_concat_pop.groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Nan values \n",
    "nans_index_t = df_concat_pop.isna().any(axis=1)\n",
    "df_concat_pop[nans_index_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNImputer - only works for numerical variables\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "df_concat_pop = imputer.fit_transform(df_concat_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_clusters = 2\n"
     ]
    }
   ],
   "source": [
    "# Apply HC on the results\n",
    "\n",
    "# !!!!! UNDERSTAND HOW DID THE NANS CAME UP !!!!!!!\n",
    "\n",
    "# Initialize the HC method\n",
    "hierarchical = AgglomerativeClustering(\n",
    "    affinity='euclidean'\n",
    ")\n",
    "\n",
    "# Find the best linkage\n",
    "for linkage in ['complete', 'average', 'single', 'ward']:\n",
    "    r2_scores[linkage] = get_r2_scores(\n",
    "        df_concat_pop, hierarchical.set_params(linkage=linkage)\n",
    "    )\n",
    "\n",
    "pd.DataFrame(r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ss(df):\n",
    "    \"\"\"Computes the sum of squares for all variables given a dataset\n",
    "    \"\"\"\n",
    "    ss = np.sum(df.var() * (df.count() - 1))\n",
    "    return ss  # return sum of sum of squares of each df variable\n",
    "\n",
    "def r2(df, labels):\n",
    "    sst = get_ss(df)\n",
    "    ssw = np.sum(df.groupby(labels).apply(get_ss))\n",
    "    return 1 - ssw/sst\n",
    "    \n",
    "def get_r2_scores(df, clusterer, min_k=2, max_k=10):\n",
    "    \"\"\"\n",
    "    Loop over different values of k. To be used with sklearn clusterers.\n",
    "    \"\"\"\n",
    "    r2_clust = {}\n",
    "    for n in range(min_k, max_k):\n",
    "        print('n_clusters =', n)\n",
    "        clust = clone(clusterer).set_params(n_clusters=n)\n",
    "        labels = clust.fit_predict(df)\n",
    "        r2_clust[n] = r2(df, labels)\n",
    "    return r2_clust\n",
    "\n",
    "if False:\n",
    "    # Set up the clusterers\n",
    "    kmeans = KMeans(\n",
    "        init='k-means++',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    hierarchical = AgglomerativeClustering(\n",
    "        affinity='euclidean'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal clusterer on individual's info and motivation variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = two_perspectives_data_imputed_no_outlier_scaled[perspective_1].copy()\n",
    "df_2 = two_perspectives_data_imputed_no_outlier_scaled[perspective_2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_clusters = 2\n",
      "n_clusters = 3\n",
      "n_clusters = 4\n",
      "n_clusters = 5\n",
      "n_clusters = 6\n",
      "n_clusters = 7\n",
      "n_clusters = 8\n",
      "n_clusters = 9\n"
     ]
    }
   ],
   "source": [
    "# Obtaining the R² scores for each cluster solution on demographic variables\n",
    "r2_scores = {}\n",
    "r2_scores['kmeans'] = get_r2_scores(df_1, kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgglomerativeClustering(linkage='complete')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clust = clone(hierarchical)\n",
    "clust.set_params(n_clusters=2, linkage='complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = clust.fit_predict(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linkage in ['complete', 'average', 'single', 'ward']:\n",
    "    r2_scores[linkage] = get_r2_scores(\n",
    "        df_1, hierarchical.set_params(linkage=linkage)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the R² scores for each cluster solution on demographic variables\n",
    "pd.DataFrame(r2_scores).plot.line(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Variables about info on individual and individual's motivation:\\nR² plot for various clustering methods\\n\", fontsize=21)\n",
    "plt.legend(title=\"Cluster methods\", title_fontsize=11)\n",
    "plt.xlabel(\"Number of clusters\", fontsize=13)\n",
    "plt.ylabel(\"R² metric\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
